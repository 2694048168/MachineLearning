{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raising-european",
   "metadata": {},
   "source": [
    "# the start of TensorFlow2 with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-concord",
   "metadata": {},
   "source": [
    "## Import TensorFlow into your program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "altered-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of TensorFlow in this source code: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"The version of TensorFlow in this source code: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-observer",
   "metadata": {},
   "source": [
    "## Load and prepare the MNIST dataset. Convert the samples from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "designed-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-accused",
   "metadata": {},
   "source": [
    "## Build the tf.keras.Sequential model by stacking layers. Choose an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpine-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-electric",
   "metadata": {},
   "source": [
    "## For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "persistent-category",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4136075 ,  0.14655066, -0.14774564, -0.06394154,  0.10493204,\n",
       "        -0.06326851, -0.26439154, -0.77751005,  0.19948927,  0.19039935]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-tolerance",
   "metadata": {},
   "source": [
    "## The tf.nn.softmax function converts these logits to \"probabilities\" for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affecting-christianity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14858353, 0.11375995, 0.08475749, 0.09216665, 0.10912259,\n",
       "        0.0922287 , 0.07542571, 0.04515178, 0.11994449, 0.11885915]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-collapse",
   "metadata": {},
   "source": [
    "## The losses.SparseCategoricalCrossentropy loss takes a vector of logits and a True index and returns a scalar loss for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corresponding-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-morning",
   "metadata": {},
   "source": [
    "## This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
    "\n",
    "## This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transparent-hormone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.383484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compound-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-ceremony",
   "metadata": {},
   "source": [
    "## The Model.fit method adjusts the model parameters to minimize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fixed-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4885 - accuracy: 0.8548\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1487 - accuracy: 0.9554\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1107 - accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0879 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0748 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b831e7ff40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "color-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demonstrated-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0739 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0739322230219841, 0.9758999943733215]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-fairy",
   "metadata": {},
   "source": [
    "## The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\n",
    "\n",
    "## If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facial-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contained-impression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.7840500e-07, 5.6254137e-08, 4.6367927e-06, 2.2723593e-04,\n",
       "        2.0170186e-10, 3.0349912e-07, 1.0412212e-14, 9.9972898e-01,\n",
       "        2.0787847e-06, 3.6401736e-05],\n",
       "       [3.4166145e-10, 3.6683690e-04, 9.9963224e-01, 8.5535191e-07,\n",
       "        3.6665138e-17, 9.5843611e-10, 3.1257275e-09, 3.6692654e-12,\n",
       "        6.0070768e-08, 9.3589820e-18],\n",
       "       [2.5792681e-06, 9.9364108e-01, 1.3594751e-03, 7.6936034e-05,\n",
       "        4.2264506e-05, 2.1628293e-06, 2.3093253e-05, 4.2100023e-03,\n",
       "        6.4037077e-04, 2.0255934e-06],\n",
       "       [9.9980754e-01, 4.7587275e-08, 2.1919164e-05, 1.6841101e-06,\n",
       "        1.0326332e-08, 2.4832196e-05, 9.1472975e-05, 4.9789514e-07,\n",
       "        3.2835689e-07, 5.1774139e-05],\n",
       "       [1.3562148e-05, 2.2025729e-08, 3.2362870e-05, 3.0106017e-07,\n",
       "        9.9154377e-01, 6.0762841e-07, 7.5223211e-06, 3.0943040e-05,\n",
       "        4.3247283e-07, 8.3705401e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-frontier",
   "metadata": {
    "tags": []
   },
   "source": [
    "# reference\n",
    "\n",
    "### https://tensorflow.google.cn/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-optics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
