{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第 18 章 概率潜在语义分析 Probabilistic Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.概率潜在语义分析是利用概率生成模型对文本集合进行话题分析的方法。概率潜在语义分析受潜在语义分析的启发提出两者可以通过矩阵分解关联起来。\n",
    "\n",
    "给定一个文本集合，通过概率潜在语义分析，可以得到各个文本生成话题的条件概率分布，以及各个话题生成单词的条件概率分布。\n",
    "\n",
    "概率潜在语义分析的模型有生成模型，以及等价的共现模型。其学习策略是观测数据的极大似然估计，其学习算法是EM算法。\n",
    "\n",
    "2.生成模型表示文本生成话题，话题生成单词从而得到单词文本共现数据的过程；假设每个文本由一个话题分布决定，每个话题由一个单词分布决定。单词变量$w$与文本变量$d$是观测变量话题变量$z$是隐变量。生成模型的定义如下：\n",
    "$$P ( T ) = \\prod _ { ( w , d ) } P ( w , d ) ^ { n ( w , d ) }$$\n",
    "$$P ( w , d ) = P ( d ) P ( w | d ) = P ( d ) \\sum _ { \\alpha } P ( z | d ) P ( w | z )$$\n",
    "3.共现模型描述文本单词共现数据拥有的模式。共现模型的定义如下：\n",
    "$$P ( T ) = \\prod _ { ( w , d ) } P ( w , d ) ^ { n ( w , d ) }$$\n",
    "$$P ( w , d ) = \\sum _ { z \\in Z } P ( z ) P ( w | z ) P ( d | z )$$\n",
    "\n",
    "4.概率潜在语义分析的模型的参数个数是$O ( M \\cdot K + N \\cdot K )$。现实中$K \\ll M$，所以概率潜在语义分析通过话题对数据进行了更简洁地表示，实现了数据压缩。\n",
    "\n",
    "5.模型中的概率分布$P ( w | d )$可以由参数空间中的单纯形表示。$M$维参数空间中，单词单纯形表示所有可能的文本的分布，在其中的话题单纯形表示在$K$个话题定义下的所有可能的文本的分布。话题单纯形是单词单纯形的子集，表示潜在语义空间。\n",
    "\n",
    "6.概率潜在语义分析的学习通常采用EM算法通过迭代学习模型的参数，$P ( w | z )$\n",
    "和$P ( z| d )$，而$P（d）$可直接统计得出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 9)\n",
      "(9, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[0,0,1,1,0,0,0,0,0], \n",
    "     [0,0,0,0,0,1,0,0,1], \n",
    "     [0,1,0,0,0,0,0,1,0], \n",
    "     [0,0,0,0,0,0,1,0,1], \n",
    "     [1,0,0,0,0,1,0,0,0], \n",
    "     [1,1,1,1,1,1,1,1,1], \n",
    "     [1,0,1,0,0,0,0,0,0], \n",
    "     [0,0,0,0,0,0,1,0,1], \n",
    "     [0,0,0,0,0,2,0,0,1], \n",
    "     [1,0,1,0,0,0,0,1,0], \n",
    "     [0,0,0,1,1,0,0,0,0]]\n",
    "\n",
    "X = np.asarray(X)\n",
    "print(X.shape)\n",
    "X = X.T\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83983869 0.71250701 0.45183393 0.33794936 0.19372614 0.57970474\n",
      "  0.34416528 0.2215177  0.36514242 0.65338927 0.86118584]\n",
      " [0.71095039 0.10896351 0.6963845  0.58948003 0.50499094 0.62095904\n",
      "  0.5042079  0.32303399 0.89803475 0.20741103 0.34065561]]\n",
      "------------------------------------\n",
      "[[3.57062081e-01 6.42937919e-01]\n",
      " [1.41847888e-10 1.00000000e+00]\n",
      " [9.99901702e-01 9.82982252e-05]\n",
      " [1.00000000e+00 6.23592304e-12]\n",
      " [1.00000000e+00 2.28213037e-14]\n",
      " [2.69885196e-01 7.30114804e-01]\n",
      " [9.56664699e-15 1.00000000e+00]\n",
      " [9.91792827e-01 8.20717330e-03]\n",
      " [4.00565093e-01 5.99434907e-01]]\n"
     ]
    }
   ],
   "source": [
    "class PLSA:\n",
    "  def __init__(self, K, max_iter):\n",
    "    self.K = K\n",
    "    self.max_iter = max_iter\n",
    "\n",
    "  def fit(self, X):\n",
    "    n_d, n_w = X.shape\n",
    "    # P(z|w,d)\n",
    "    p_z_dw = np.zeros((n_d, n_w, self.K))\n",
    "    # P(z|d)\n",
    "    p_z_d = np.random.rand(n_d, self.K)\n",
    "    # P(w|z)\n",
    "    p_w_z = np.random.rand(self.K, n_w)\n",
    "    for i_iter in range(self.max_iter):\n",
    "      # E step\n",
    "      for di in range(n_d):\n",
    "        for wi in range(n_w):\n",
    "          sum_zk = np.zeros((self.K))\n",
    "          for zi in range(self.K):\n",
    "            sum_zk[zi] = p_z_d[di, zi] * p_w_z[zi, wi]\n",
    "          sum1 = np.sum(sum_zk)\n",
    "          if sum1 == 0:\n",
    "            sum1 = 1\n",
    "          for zi in range(self.K):\n",
    "            p_z_dw[di, wi, zi] = sum_zk[zi] / sum1\n",
    "      # M step\n",
    "      # update P(z|d)\n",
    "      for di in range(n_d):\n",
    "        for zi in range(self.K):\n",
    "          sum1 = 0.\n",
    "          sum2 = 0.\n",
    "          for wi in range(n_w):\n",
    "            sum1 = sum1 + X[di, wi] * p_z_dw[di, wi, zi]\n",
    "            sum2 = sum2 + X[di, wi]\n",
    "          if sum2 == 0:\n",
    "            sum2 = 1\n",
    "          p_z_d[di, zi] = sum1 / sum2\n",
    "\n",
    "      # update P(w|z)\n",
    "      for zi in range(self.K):\n",
    "        sum2 = np.zeros((n_w))\n",
    "        for wi in range(n_w):\n",
    "          for di in range(n_d):\n",
    "            sum2[wi] = sum2[wi] + X[di, wi] * p_z_dw[di, wi, zi]\n",
    "        sum1 = np.sum(sum2)\n",
    "        if sum1 == 0:\n",
    "          sum1 = 1\n",
    "          for wi in range(n_w):\n",
    "            p_w_z[zi, wi] = sum2[wi] / sum1\n",
    "    return p_w_z, p_z_d\n",
    "  \n",
    "# -------------------------------\n",
    "# TEST\n",
    "model = PLSA(2, 100)\n",
    "p_w_z, p_z_d = model.fit(X)\n",
    "print(p_w_z)\n",
    "print(\"------------------------------------\")\n",
    "print(p_z_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
