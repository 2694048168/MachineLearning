{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e9d193",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390565e7",
   "metadata": {},
   "source": [
    "# Case Study | Image Classification with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511372aa",
   "metadata": {},
   "source": [
    "## 1. Downloading the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf733b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=tfds.as_numpy(tfds.load('mnist',split=['train', 'test'], \n",
    "                                                          batch_size=-1, #all data in single batch\n",
    "                                                          as_supervised=True, #only input and label\n",
    "                                                          shuffle_files=True #shuffle data to randomize\n",
    "                                                         ))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47f22087",
   "metadata": {},
   "source": [
    "tfds.load(\n",
    "    name: str,\n",
    "    *,\n",
    "    split: Optional[Tree[splits_lib.Split]] = None,\n",
    "    data_dir: Optional[str] = None,\n",
    "    batch_size: tfds.typing.Dim = None,\n",
    "    shuffle_files: bool = False,\n",
    "    download: bool = True,\n",
    "    as_supervised: bool = False,\n",
    "    decoders: Optional[TreeDict[decode.Decoder]] = None,\n",
    "    read_config: Optional[tfds.ReadConfig] = None,\n",
    "    with_info: bool = False,\n",
    "    builder_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    download_and_prepare_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    as_dataset_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    try_gcs: bool = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8b25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27fb728bca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_index = 7777 #You may pick a number up to 60,000\n",
    "print(\"The digit in the image:\", y_train[img_index])\n",
    "plt.imshow(x_train[img_index].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a63e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6f6b9",
   "metadata": {},
   "source": [
    "## 2. Reshaping and Normalizing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d27f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the grayscale RGB codes by dividing it to the \"max minus min grayscale RGB value\".\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122aca0a",
   "metadata": {},
   "source": [
    "## 3. Building the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dd1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D\n",
    "\n",
    "#Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28,kernel_size=(3,3), input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) #Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128,activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db4d67",
   "metadata": {},
   "source": [
    "## 4. Compiling and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86159ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 2ms/step - loss: 0.3702 - accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0965 - accuracy: 0.9713\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0637 - accuracy: 0.9800\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0449 - accuracy: 0.9860\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0317 - accuracy: 0.9895\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0238 - accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0211 - accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0172 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0155 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27fb7a98f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646c182",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54fe29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05709945037961006, 0.9864000082015991]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36fbf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our CNN model predicts that the digit in the image is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also make individual predictions with the following code:\n",
    "img_pred_index = 1000\n",
    "plt.imshow(x_test[img_pred_index].reshape(28,28),cmap='Greys')\n",
    "pred = model.predict(x_test[img_pred_index].reshape(1,28,28,1))\n",
    "print(\"Our CNN model predicts that the digit in the image is:\",pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ac83a",
   "metadata": {},
   "source": [
    "## 6. Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ae79d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/digit_classifier\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/digit_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "# Create a 'saved_model' folder under the 'content' folder of your Google Colab Directory.\n",
    "# Save the full model with its variables, weights, and biases.\n",
    "model.save('saved_model/digit_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2090f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
