{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "### Deep Learning\n",
    "### Neural Networks\n",
    "### 环境搭建详细教程\n",
    "- Windows 10\n",
    "- Ubuntu 18.04/16.04/20.04\n",
    "- TensorFlow\n",
    "- PyTorch\n",
    "- CUDA cuDNN\n",
    "- Jupyter Lab & Jupyter Notebook\n",
    "- PyCharm\n",
    "\n",
    "[环境搭建详细教程——GitHub-Blog](https://2694048168.github.io/)\n",
    "\n",
    "[环境搭建详细教程——Gitee-Blog](http://weili_yzzcq.gitee.io/)\n",
    "\n",
    "[环境搭建详细教程——CSDN-Blog](https://blog.csdn.net/weixin_46782218)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, w = 0, error = 5565.107834483211\n",
      "Running\n",
      "After 1000 iterations b = 0.08893651993741346, w = 1.4777440851894448, error = 112.61481011613473\n"
     ]
    }
   ],
   "source": [
    "# 线性回归\n",
    "# make decisions: discrete 离散值     continuous 连续值\n",
    "# continuous prediction：input data（x）；prediction（f，参数 θ theta）；real data，ground-truth（y）\n",
    "# linear equation 线性方程组 y = w * x + b + epsilon\n",
    "# with noise  epsilon 噪声 高斯分布\n",
    "# find the W and b\n",
    "# loss = (WX + b - Y)**2\n",
    "# miniize loss \n",
    "# gradient descent GD 梯度下降 一维和二维可视化\n",
    "# loss surface\n",
    "# linear regression\n",
    "# logistic regression\n",
    "# classification\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 生成 csv 文件里面的数据\n",
    "# data = []\n",
    "# for i in range(100):\n",
    "# \tx = np.random.uniform(3., 12.)\n",
    "# \t# mean=0, std=0.1\n",
    "# \teps = np.random.normal(0., 0.1)\n",
    "# \ty = 1.477 * x + 0.089 + eps\n",
    "# \tdata.append([x, y])\n",
    "# data = np.array(data)\n",
    "# print(data.shape, data)\n",
    "\n",
    "# cpmputer loss\n",
    "# Y = W*X +b\n",
    "def computer_error_for_line_given_points(b, w, points):\n",
    "    total_error = 0\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # computer mean-squared-error\n",
    "        total_error += ((w * x + b) - y) ** 2\n",
    "        # total_error += (y - (w * x + b)) ** 2\n",
    "    # average loss for each point\n",
    "    return total_error / float(len(points))\n",
    "\n",
    "# computer Gradient and update\n",
    "def step_gradient(b_current, w_current, points, learning_rate):\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # grad_b = 2(wx + b - y)\n",
    "        b_gradient += (2/N) * ((w_current * x + b_current) - y)\n",
    "        # grad_w = 2(wx + b - y) * x\n",
    "        w_gradient += (2/N) * x * ((w_current * x + b_current) - y)\n",
    "    # update the grad_w, and the grad_b\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_w = w_current - (learning_rate * w_gradient)\n",
    "    return [new_b, new_w]\n",
    "\n",
    "# set w = w_new and loop\n",
    "def gradient_descent_runner(points, starting_b, starting_w, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    # update for several times\n",
    "    for i in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), learning_rate)\n",
    "    return [b, w]\n",
    "\n",
    "\n",
    "# running the linear regression model\n",
    "# loading the data for numpy from the data.cvs file\n",
    "# the data shape is 100 * 2 (row * column)\n",
    "points = np.genfromtxt(\"./datasets/data.csv\", delimiter=\",\")\n",
    "# init the Hyperparameter\n",
    "learning_rate = 0.0001\n",
    "initial_b = 0\n",
    "initial_w = 0\n",
    "num_iterations = 1000\n",
    "# show the initial Hyperparameter for linear regression model and the error\n",
    "print(\"Starting gradient descent at b = {0}, w = {1}, error = {2}\"\n",
    "      .format(initial_b, initial_w, computer_error_for_line_given_points(initial_b, initial_w, points)))\n",
    "\n",
    "print(\"Running\")\n",
    "# iterations = 1000,computer the Hyperparameter for linear regression model\n",
    "[b, w] = gradient_descent_runner(points, initial_b, initial_w, learning_rate, num_iterations)\n",
    "\n",
    "# and show the Hyperparameter for linear regression model and the error\n",
    "print(\"After {0} iterations b = {1}, w = {2}, error = {3}\"\n",
    "      .format(num_iterations, b, w, computer_error_for_line_given_points(b, w, points)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n",
      "0 0 2.145007\n",
      "0 100 0.9779064\n",
      "0 200 0.8011861\n",
      "1 0 0.682101\n",
      "1 100 0.68953323\n",
      "1 200 0.59687996\n",
      "2 0 0.5544969\n",
      "2 100 0.60021234\n",
      "2 200 0.5208171\n",
      "3 0 0.49560317\n",
      "3 100 0.5510172\n",
      "3 200 0.4770015\n",
      "4 0 0.45830703\n",
      "4 100 0.51574916\n",
      "4 200 0.44660082\n",
      "5 0 0.4310113\n",
      "5 100 0.48866108\n",
      "5 200 0.42332447\n",
      "6 0 0.40955436\n",
      "6 100 0.46667328\n",
      "6 200 0.40453193\n",
      "7 0 0.3919871\n",
      "7 100 0.44810033\n",
      "7 200 0.38870093\n",
      "8 0 0.37698773\n",
      "8 100 0.4321654\n",
      "8 200 0.3749433\n",
      "9 0 0.3639257\n",
      "9 100 0.41827995\n",
      "9 200 0.3629041\n",
      "10 0 0.35239592\n",
      "10 100 0.40607452\n",
      "10 200 0.35226172\n",
      "11 0 0.34209\n",
      "11 100 0.39520663\n",
      "11 200 0.34277108\n",
      "12 0 0.33278885\n",
      "12 100 0.38533977\n",
      "12 200 0.33422118\n",
      "13 0 0.3244313\n",
      "13 100 0.37634808\n",
      "13 200 0.32637382\n",
      "14 0 0.3167131\n",
      "14 100 0.3681502\n",
      "14 200 0.3191441\n",
      "15 0 0.30964595\n",
      "15 100 0.36062518\n",
      "15 200 0.31245127\n",
      "16 0 0.30311885\n",
      "16 100 0.3536573\n",
      "16 200 0.30619872\n",
      "17 0 0.2970287\n",
      "17 100 0.34722012\n",
      "17 200 0.3003191\n",
      "18 0 0.29140472\n",
      "18 100 0.34124565\n",
      "18 200 0.29482606\n",
      "19 0 0.28617287\n",
      "19 100 0.33563197\n",
      "19 200 0.28969684\n",
      "20 0 0.28127086\n",
      "20 100 0.33038154\n",
      "20 200 0.28484973\n",
      "21 0 0.27660605\n",
      "21 100 0.32542306\n",
      "21 200 0.280265\n",
      "22 0 0.27215695\n",
      "22 100 0.32068706\n",
      "22 200 0.27590075\n",
      "23 0 0.26799193\n",
      "23 100 0.31619698\n",
      "23 200 0.27178058\n",
      "24 0 0.26402566\n",
      "24 100 0.3118977\n",
      "24 200 0.26785937\n",
      "25 0 0.26028073\n",
      "25 100 0.307815\n",
      "25 200 0.26411417\n",
      "26 0 0.25673878\n",
      "26 100 0.3039063\n",
      "26 200 0.26061907\n",
      "27 0 0.25335112\n",
      "27 100 0.3001855\n",
      "27 200 0.25728583\n",
      "28 0 0.25014195\n",
      "28 100 0.29665297\n",
      "28 200 0.25410765\n",
      "29 0 0.2471003\n",
      "29 100 0.29328233\n",
      "29 200 0.25104755\n"
     ]
    }
   ],
   "source": [
    "# Image Classification\n",
    "# hand-written digits recognition\n",
    "# MNIST: 7,000 images per category = 70,000\n",
    "# train / test splitting = 60k / 10k\n",
    "# [28, 28, 1] = [rows,columns, gray_value]\n",
    "# 28 * 28 = 784 转换为一维数组\n",
    "# input and output\n",
    "# coding the features for data: one-hot\n",
    "# regression VS classification\n",
    "# y = w * x + b\n",
    "# y 属于空间 R^d\n",
    "# out = X @ W + b\n",
    "# out:[0.1, 0.8, 0.02,.0.08] = 1 概率，最大值概率称之为置信度\n",
    "# pred = argmax(out)\n",
    "\n",
    "# out = X @ W + b\n",
    "# X = [b, 784]\n",
    "# W = [784, 10]\n",
    "# b = [10]\n",
    "\n",
    "# it is linear !\n",
    "# out = X @ W + b\n",
    "# 变成 non-linear !\n",
    "# out = f(X @ W + b)\n",
    "# 引入非线性因子，这个 f 函数称之为激活函数，\n",
    "# f = ReLu function and sigmoid function\n",
    "# out = relu(X @ W + b)\n",
    "\n",
    "# it is simple\n",
    "# out = relu(X @ W + b)\n",
    "# 添加隐藏层 hide layer\n",
    "# h1 = relu(X @ W1 + b1)\n",
    "# h2 = relu(X @ W2 + b2)\n",
    "# out = relu(X @ W3 + b3)\n",
    "\n",
    "# particularly\n",
    "# 每一层都是类似降维的过程，直到从 [1, 784] ---- [1, 10]\n",
    "# X = [v1, v2, ... , v784]\n",
    "# h1 = relu(X @ W1 + b1)\n",
    "#    W1: [784, 512]\n",
    "#    b1: [1, 512]\n",
    "# h2 = relu(X @ W2 + b2)\n",
    "#    W2: [512, 256]\n",
    "#    b2: [1, 256]\n",
    "# out = relu(X @ W3 + b3)\n",
    "#    W2: [256, 10]\n",
    "#    b2: [1, 10]\n",
    "\n",
    "# loss\n",
    "# out:[1, 10]\n",
    "# Y/label: 0-9 （one-hot）\n",
    "# euclidean distance 计算欧式距离 使得 out 接近 label   MSE\n",
    "# loss = (Y - out) **2\n",
    "\n",
    "# in a nutshell\n",
    "# out = relu{relu{relu[X @ W1 + b1] @ W2 + b2 } @ W3 + b3}\n",
    "# pred = argmax(out)\n",
    "# loss = MSE(out, label)\n",
    "# minimize loss\n",
    "# [w1_new, b2_new, w2_new, b2_new, w3_new, b3_new]\n",
    "\n",
    "# Deep Learning\n",
    "# classification precedure\n",
    "# step1 compute [h1, h2, out]\n",
    "# step2 compute loss\n",
    "# step3 compute gradient and update [w1_new, b2_new, w2_new, b2_new, w3_new, b3_new]\n",
    "# step4 loop\n",
    "# need TensorFlow\n",
    "\n",
    "# 以下两条语句，使得 TensorFlow 少打印出一些无关紧要的信息\n",
    "# import  os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "# step 0 loading data X and Y\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data() \n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "print(x.shape, y.shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# batch 概念\n",
    "train_dataset = train_dataset.batch(200)\n",
    "    \n",
    "# step 0 model NN\n",
    "model = tf.keras.Sequential([layers.Dense(512, activation=\"relu\"),\n",
    "                          layers.Dense(256, activation=\"relu\"),\n",
    "                          layers.Dense(10)])\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# 对整个训练集 训练 30 次，即就是 epoch = 30 \n",
    "# 将训练集数据划分为每次读取 200 ，即就是 batch = 200\n",
    "# 那么 step = train_data / batch = 60k / 200 = 300\n",
    "# 每训练 100 个样本数据，就查看一次训练情况 loss\n",
    "# 实际显示的 loss 情况次数 = epoch * (step / 100) = 30 * (300/100) = 90\n",
    "\n",
    "# step4 loop\n",
    "# 对一个数据集 dataset 训练一次称之为 epoch\n",
    "def train_epoch(epoch):\n",
    "    # 对一个 batch 训练一次称之为 step\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # [b， 28， 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # step 1 compute output\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = model(x)\n",
    "            # step2 compute loss\n",
    "            loss = tf.reduce_sum(tf.square(out - y)) / x.shape[0]\n",
    "            \n",
    "        # step 3 optimize and update w1, w2, w3, b1, b2, b3\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # w_new = w - lr * grad\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables)) \n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            # print(epoch, step, 'loss:', loss.numpy())\n",
    "            print(\"第 {0} 次 epoch，第 {1} step，该次训练 loss = {2}\".format(epoch, step+100, loss.numpy()))\n",
    "\n",
    "# 对整个数据集训练多次 30 次\n",
    "for epoch in range(30):\n",
    "    train_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow 数据类型\n",
    "# data container: list, np.array, tf.Tensor\n",
    "# what is Tensor\n",
    "# - scalar 标量 1.1\n",
    "# - vector 向量 [1.1], [1.1, 2.2]\n",
    "# - matrix 矩阵 [[1.1, 2.2], [3.3, 4.4], [5.5, 6.6]]\n",
    "# - tensor rank > 2 矩阵的秩\n",
    "# TF is a computing lib\n",
    "# - int, float, double, bool, string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# create the int, float, double, bool, string\n",
    "tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(1.2, dtype=tf.int32)\n",
    "# TypeError: Cannot convert 1.2 to EagerTensor of dtype int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello World'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor Property 常见属性\n",
    "with tf.device(\"cpu\"):\n",
    "    const_cpu = tf.constant([1])\n",
    "\n",
    "with tf.device(\"gpu\"):\n",
    "    const_gpu = tf.range(4)\n",
    "    \n",
    "# device 属性，查看 Tensor 在哪一个设备上 CPU or GPU\n",
    "const_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_gpu.device\n",
    "# 因为本地没有安装 GPU 加速驱动 CUDA 和 cuDNN\n",
    "# 无法提供 GPU 加速环境，故此工作环境依旧还在 CPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相互转换 \n",
    "# const_cpu_to_gpu = const_cpu.gpu()\n",
    "# const_cpu_to_gpu.device\n",
    "\n",
    "const_gpu_to_cpu = tf.identity(const_gpu)\n",
    "const_gpu_to_cpu.device\n",
    "\n",
    "# tensor 的计算必须在同一设备进行，全部都是 CPU 或者全部都是 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 属性，将 Tensor 转换为 numpy\n",
    "# numpy 是在 CPU 上的\n",
    "const_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 Tensor 的 shape 维度\n",
    "# ndim 属性，返回 Tensor 的维度信息\n",
    "# rank 方法，返回 Tensor 的维度信息\n",
    "const_cpu.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(const_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(tf.ones([3, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判断是否 Tensor\n",
    "tf.is_tensor(const_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为 Tensor\n",
    "const = np.arange(5)\n",
    "const_tensor = tf.convert_to_tensor(const)\n",
    "const_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dtype\n",
    "# 数值类型之间的转换\n",
    "const_cpu.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(const_tensor, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float64, numpy=array([0., 1., 2., 3., 4.])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(const_tensor, dtype=tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(const_tensor, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int <==> bool\n",
    "bool_num = tf.constant([0, 1])\n",
    "bool_num_bool = tf.cast(bool_num, dtype=tf.bool)\n",
    "bool_num_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(bool_num_bool, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.Variable\n",
    "# 一般是需要优化的变量参数\n",
    "a = tf.range(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=int32, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variable:0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.trainable\n",
    "# 需要梯度信息，可以自动求导\n",
    "# 神经网络的参数需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Tensor\n",
    "# from numpy, list\n",
    "# zeros, ones\n",
    "# fill\n",
    "# random\n",
    "# constant\n",
    "# Applicatin\n",
    "\n",
    "# meta-learning\n",
    "\n",
    "# Tensor 索引和切片\n",
    "# selecetive indexing\n",
    "# tf.gather() , tf.gather_nd(), tf.boolean_mask()\n",
    "\n",
    "# 维度变换\n",
    "# shape, ndim\n",
    "# reshape\n",
    "# expand_dims, squeeze\n",
    "# transpose\n",
    "# broadcast_to\n",
    "\n",
    "# 数学计算\n",
    "# +, -, *, /, **, pow, square, sqrt, //, %, exp, log, @, matmul\n",
    "# element_wise, matrix_wise, dim_wise, \n",
    "# 元素级计算，矩阵级计算，维度级计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(255.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# import  os\n",
    "# 复制 0， 1， 2，打印 c++ 一些信息\n",
    "# 0 打印全部信息\n",
    "# 2 只打印 error 信息\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "# loading the dataset MNIST\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "\n",
    "# set the iteration\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n",
      "batch (128, 28, 28) (128,)\n",
      "0 0 loss 0.42511042952537537\n",
      "0 100 loss 0.1789942979812622\n",
      "0 200 loss 0.16580988466739655\n",
      "0 300 loss 0.1560211181640625\n",
      "0 400 loss 0.1542573869228363\n",
      "1 0 loss 0.1479978859424591\n",
      "1 100 loss 0.1321682631969452\n",
      "1 200 loss 0.13824641704559326\n",
      "1 300 loss 0.13372421264648438\n",
      "1 400 loss 0.13392488658428192\n",
      "2 0 loss 0.12848277390003204\n",
      "2 100 loss 0.11817771196365356\n",
      "2 200 loss 0.12388703972101212\n",
      "2 300 loss 0.11938042938709259\n",
      "2 400 loss 0.12050290405750275\n",
      "3 0 loss 0.11577292531728745\n",
      "3 100 loss 0.10877491533756256\n",
      "3 200 loss 0.11369021236896515\n",
      "3 300 loss 0.1092468723654747\n",
      "3 400 loss 0.11090860515832901\n",
      "4 0 loss 0.10678441822528839\n",
      "4 100 loss 0.10189224779605865\n",
      "4 200 loss 0.10604660212993622\n",
      "4 300 loss 0.10167856514453888\n",
      "4 400 loss 0.10369563102722168\n",
      "5 0 loss 0.0999135747551918\n",
      "5 100 loss 0.09662076085805893\n",
      "5 200 loss 0.10006420314311981\n",
      "5 300 loss 0.0957786813378334\n",
      "5 400 loss 0.09803612530231476\n",
      "6 0 loss 0.0944289118051529\n",
      "6 100 loss 0.09243079274892807\n",
      "6 200 loss 0.09519816935062408\n",
      "6 300 loss 0.09105338156223297\n",
      "6 400 loss 0.09347577393054962\n",
      "7 0 loss 0.08995360136032104\n",
      "7 100 loss 0.08898767083883286\n",
      "7 200 loss 0.09114708006381989\n",
      "7 300 loss 0.08714453876018524\n",
      "7 400 loss 0.0896892100572586\n",
      "8 0 loss 0.08621992915868759\n",
      "8 100 loss 0.08607572317123413\n",
      "8 200 loss 0.08771105855703354\n",
      "8 300 loss 0.08386079967021942\n",
      "8 400 loss 0.08645957708358765\n",
      "9 0 loss 0.08304877579212189\n",
      "9 100 loss 0.08354615420103073\n",
      "9 200 loss 0.08477957546710968\n",
      "9 300 loss 0.08105111122131348\n",
      "9 400 loss 0.08372876793146133\n"
     ]
    }
   ],
   "source": [
    "# 前向传播 forward\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# loading data\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "\n",
    "# convert to Tensor\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "# show the info\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the dataset and split the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print(\"batch\", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 权值\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "# tf.Variable 才会自动记录梯度信息，tf.Tensor 不会记录梯度信息，故此值为 None，类型为 NoneType\n",
    "# 需要给一个好点的初始值，否则容易 loss 爆炸，出现 nan(not a number) 情况,stddev=0.1 方差给小一点\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 学习率 ，步长 10^-3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 对数据集迭代 10 次\n",
    "for epoch in range(10):\n",
    "    # 对数据集一次循环\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x [128, 28, 28]\n",
    "        # y [128]\n",
    "        # 进行维度转换 [128, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])   \n",
    "    \n",
    "        # 自动求导过程,梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            # x [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            # 添加非线性，relu 激活函数\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 +b3\n",
    "        \n",
    "            # compute loss\n",
    "            # out [b, 10]\n",
    "            # y [b] => [b, 10]\n",
    "            y_one_hot = tf.one_hot(y, depth=10)\n",
    "        \n",
    "            # MSE = mean((y - out)**2)\n",
    "            loss = tf.square(y_one_hot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "    \n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # 原地更新，否则就返回 tf.Tensor 类型了，无法进行下一个梯度更新\n",
    "        # w1 = w1 - learning_rate * grads[0]\n",
    "        w1.assign_sub(learning_rate * grads[0])\n",
    "        b1.assign_sub(learning_rate * grads[1])\n",
    "        w2.assign_sub(learning_rate * grads[2])\n",
    "        b2.assign_sub(learning_rate * grads[3])\n",
    "        w3.assign_sub(learning_rate * grads[4])\n",
    "        b3.assign_sub(learning_rate * grads[5])\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, \"loss\", float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 张量的合并和分割\n",
    "# tf.concat 合并\n",
    "# tf.split  分割\n",
    "# tf.stack 合并\n",
    "# tf.unstack 分割\n",
    "\n",
    "# 数据统计\n",
    "# tf.norm 范数概念\n",
    "# tf.reduce_min/max/mean\n",
    "# tf.argmax/argminx\n",
    "# tf.equal\n",
    "# tf.unique\n",
    "\n",
    "# 张量排序 Tensor 排序\n",
    "# tf.sort、tf.argsort\n",
    "# top_k\n",
    "# top_k compute of accuracy\n",
    "\n",
    "# 填充与复制\n",
    "# pad\n",
    "# tile\n",
    "# broadcast_to\n",
    "\n",
    "# 张量限幅\n",
    "# clip_by_value\n",
    "# relu\n",
    "# clip_by_norm\n",
    "# gradient clipping\n",
    "\n",
    "# 高阶操作\n",
    "# where\n",
    "# scatter_nd\n",
    "# meshgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n",
      "batch (128, 28, 28) (128,)\n",
      "0 0 loss 0.38115018606185913\n",
      "0 100 loss 0.2140667885541916\n",
      "0 200 loss 0.17352941632270813\n",
      "0 300 loss 0.17252981662750244\n",
      "0 400 loss 0.1654943823814392\n",
      "test acc :  0.1447\n",
      "1 0 loss 0.155382439494133\n",
      "1 100 loss 0.1564989537000656\n",
      "1 200 loss 0.1401979923248291\n",
      "1 300 loss 0.14494988322257996\n",
      "1 400 loss 0.1413814276456833\n",
      "test acc :  0.1958\n",
      "2 0 loss 0.13282153010368347\n",
      "2 100 loss 0.13779962062835693\n",
      "2 200 loss 0.12248848378658295\n",
      "2 300 loss 0.12837831676006317\n",
      "2 400 loss 0.12546643614768982\n",
      "test acc :  0.2617\n",
      "3 0 loss 0.11781013011932373\n",
      "3 100 loss 0.1250159740447998\n",
      "3 200 loss 0.11026396602392197\n",
      "3 300 loss 0.11668787151575089\n",
      "3 400 loss 0.11417224258184433\n",
      "test acc :  0.3339\n",
      "4 0 loss 0.10710453987121582\n",
      "4 100 loss 0.11570942401885986\n",
      "4 200 loss 0.10131652653217316\n",
      "4 300 loss 0.10808267444372177\n",
      "4 400 loss 0.105748750269413\n",
      "test acc :  0.3906\n",
      "5 0 loss 0.09909947216510773\n",
      "5 100 loss 0.10840018093585968\n",
      "5 200 loss 0.09452857077121735\n",
      "5 300 loss 0.10141358524560928\n",
      "5 400 loss 0.09917517006397247\n",
      "test acc :  0.4394\n",
      "6 0 loss 0.0928255096077919\n",
      "6 100 loss 0.10247411578893661\n",
      "6 200 loss 0.08917931467294693\n",
      "6 300 loss 0.09608200192451477\n",
      "6 400 loss 0.09400992095470428\n",
      "test acc :  0.4765\n",
      "7 0 loss 0.08775044977664948\n",
      "7 100 loss 0.09758851677179337\n",
      "7 200 loss 0.08487435430288315\n",
      "7 300 loss 0.0917344018816948\n",
      "7 400 loss 0.08983373641967773\n",
      "test acc :  0.5093\n",
      "8 0 loss 0.08355022966861725\n",
      "8 100 loss 0.09345561265945435\n",
      "8 200 loss 0.08127716183662415\n",
      "8 300 loss 0.08807353675365448\n",
      "8 400 loss 0.08636192977428436\n",
      "test acc :  0.5352\n",
      "9 0 loss 0.08004598319530487\n",
      "9 100 loss 0.08989448845386505\n",
      "9 200 loss 0.07824313640594482\n",
      "9 300 loss 0.08493747562170029\n",
      "9 400 loss 0.08345197141170502\n",
      "test acc :  0.5571\n",
      "10 0 loss 0.07705165445804596\n",
      "10 100 loss 0.08678595721721649\n",
      "10 200 loss 0.0756436213850975\n",
      "10 300 loss 0.08224496245384216\n",
      "10 400 loss 0.08092234283685684\n",
      "test acc :  0.5747\n",
      "11 0 loss 0.07441703230142593\n",
      "11 100 loss 0.08403900265693665\n",
      "11 200 loss 0.07335633039474487\n",
      "11 300 loss 0.07990600913763046\n",
      "11 400 loss 0.07867644727230072\n",
      "test acc :  0.5941\n",
      "12 0 loss 0.07211394608020782\n",
      "12 100 loss 0.08158200979232788\n",
      "12 200 loss 0.07134275138378143\n",
      "12 300 loss 0.07783723622560501\n",
      "12 400 loss 0.07668007165193558\n",
      "test acc :  0.6114\n",
      "13 0 loss 0.0700608417391777\n",
      "13 100 loss 0.0793977752327919\n",
      "13 200 loss 0.06954559683799744\n",
      "13 300 loss 0.07597361505031586\n",
      "13 400 loss 0.07488047331571579\n",
      "test acc :  0.6253\n",
      "14 0 loss 0.06824599206447601\n",
      "14 100 loss 0.07743702828884125\n",
      "14 200 loss 0.06793345510959625\n",
      "14 300 loss 0.07425446063280106\n",
      "14 400 loss 0.07327115535736084\n",
      "test acc :  0.6381\n",
      "15 0 loss 0.06660370528697968\n",
      "15 100 loss 0.07566101104021072\n",
      "15 200 loss 0.06647977977991104\n",
      "15 300 loss 0.07267196476459503\n",
      "15 400 loss 0.07180460542440414\n",
      "test acc :  0.6469\n",
      "16 0 loss 0.06510435044765472\n",
      "16 100 loss 0.07405555993318558\n",
      "16 200 loss 0.06515373289585114\n",
      "16 300 loss 0.07121490687131882\n",
      "16 400 loss 0.07045447081327438\n",
      "test acc :  0.6563\n",
      "17 0 loss 0.06374146044254303\n",
      "17 100 loss 0.07258890569210052\n",
      "17 200 loss 0.06391996145248413\n",
      "17 300 loss 0.06987211108207703\n",
      "17 400 loss 0.06921040266752243\n",
      "test acc :  0.6664\n",
      "18 0 loss 0.06248990446329117\n",
      "18 100 loss 0.07123509794473648\n",
      "18 200 loss 0.0627775564789772\n",
      "18 300 loss 0.06864247471094131\n",
      "18 400 loss 0.0680684894323349\n",
      "test acc :  0.6768\n",
      "19 0 loss 0.06133512407541275\n",
      "19 100 loss 0.06997664272785187\n",
      "19 200 loss 0.06172039359807968\n",
      "19 300 loss 0.06750530749559402\n",
      "19 400 loss 0.06701908260583878\n",
      "test acc :  0.6854\n",
      "20 0 loss 0.060278356075286865\n",
      "20 100 loss 0.06880421936511993\n",
      "20 200 loss 0.06074480339884758\n",
      "20 300 loss 0.06643931567668915\n",
      "20 400 loss 0.06604793667793274\n",
      "test acc :  0.6929\n",
      "21 0 loss 0.05930075794458389\n",
      "21 100 loss 0.06770424544811249\n",
      "21 200 loss 0.05983210355043411\n",
      "21 300 loss 0.06543797254562378\n",
      "21 400 loss 0.06512323766946793\n",
      "test acc :  0.7007\n",
      "22 0 loss 0.05838370323181152\n",
      "22 100 loss 0.06667597591876984\n",
      "22 200 loss 0.05897524207830429\n",
      "22 300 loss 0.06450088322162628\n",
      "22 400 loss 0.06424987316131592\n",
      "test acc :  0.7059\n",
      "23 0 loss 0.05752246454358101\n",
      "23 100 loss 0.06571599841117859\n",
      "23 200 loss 0.05816458538174629\n",
      "23 300 loss 0.06362030655145645\n",
      "23 400 loss 0.06343315541744232\n",
      "test acc :  0.7116\n",
      "24 0 loss 0.05671171098947525\n",
      "24 100 loss 0.06480778008699417\n",
      "24 200 loss 0.057399481534957886\n",
      "24 300 loss 0.06278723478317261\n",
      "24 400 loss 0.06265544146299362\n",
      "test acc :  0.717\n",
      "25 0 loss 0.05595047399401665\n",
      "25 100 loss 0.0639498233795166\n",
      "25 200 loss 0.05667787790298462\n",
      "25 300 loss 0.061995841562747955\n",
      "25 400 loss 0.061922479420900345\n",
      "test acc :  0.7237\n",
      "26 0 loss 0.05523594468832016\n",
      "26 100 loss 0.06314895302057266\n",
      "26 200 loss 0.05599508434534073\n",
      "26 300 loss 0.06124423071742058\n",
      "26 400 loss 0.06122912839055061\n",
      "test acc :  0.7278\n",
      "27 0 loss 0.05456118658185005\n",
      "27 100 loss 0.0623927041888237\n",
      "27 200 loss 0.0553477481007576\n",
      "27 300 loss 0.060527123510837555\n",
      "27 400 loss 0.06057377904653549\n",
      "test acc :  0.7328\n",
      "28 0 loss 0.05391637235879898\n",
      "28 100 loss 0.06168699264526367\n",
      "28 200 loss 0.05472429469227791\n",
      "28 300 loss 0.05984686687588692\n",
      "28 400 loss 0.05994900315999985\n",
      "test acc :  0.7373\n",
      "29 0 loss 0.05330028384923935\n",
      "29 100 loss 0.06101897358894348\n",
      "29 200 loss 0.054127972573041916\n",
      "29 300 loss 0.059199970215559006\n",
      "29 400 loss 0.059349846094846725\n",
      "test acc :  0.7416\n",
      "30 0 loss 0.05270889401435852\n",
      "30 100 loss 0.060382891446352005\n",
      "30 200 loss 0.053558506071567535\n",
      "30 300 loss 0.05858476087450981\n",
      "30 400 loss 0.0587819442152977\n",
      "test acc :  0.7467\n",
      "31 0 loss 0.052144359797239304\n",
      "31 100 loss 0.059779126197099686\n",
      "31 200 loss 0.05301126837730408\n",
      "31 300 loss 0.057996414601802826\n",
      "31 400 loss 0.05823702737689018\n",
      "test acc :  0.7501\n",
      "32 0 loss 0.05160559341311455\n",
      "32 100 loss 0.05920390412211418\n",
      "32 200 loss 0.052489589899778366\n",
      "32 300 loss 0.05743228271603584\n",
      "32 400 loss 0.05772050470113754\n",
      "test acc :  0.7536\n",
      "33 0 loss 0.05108598619699478\n",
      "33 100 loss 0.05865227058529854\n",
      "33 200 loss 0.05199173837900162\n",
      "33 300 loss 0.0568876676261425\n",
      "33 400 loss 0.05722380802035332\n",
      "test acc :  0.7571\n",
      "34 0 loss 0.050588082522153854\n",
      "34 100 loss 0.05812184885144234\n",
      "34 200 loss 0.05151171609759331\n",
      "34 300 loss 0.05636397749185562\n",
      "34 400 loss 0.05674329400062561\n",
      "test acc :  0.7603\n",
      "35 0 loss 0.05010852962732315\n",
      "35 100 loss 0.05761328339576721\n",
      "35 200 loss 0.05105356127023697\n",
      "35 300 loss 0.05586067587137222\n",
      "35 400 loss 0.056281525641679764\n",
      "test acc :  0.7635\n",
      "36 0 loss 0.0496474988758564\n",
      "36 100 loss 0.05712847039103508\n",
      "36 200 loss 0.0506146065890789\n",
      "36 300 loss 0.055375099182128906\n",
      "36 400 loss 0.05583874136209488\n",
      "test acc :  0.7668\n",
      "37 0 loss 0.0492032915353775\n",
      "37 100 loss 0.05666247755289078\n",
      "37 200 loss 0.05019441992044449\n",
      "37 300 loss 0.05490853264927864\n",
      "37 400 loss 0.055410586297512054\n",
      "test acc :  0.7705\n",
      "38 0 loss 0.048772990703582764\n",
      "38 100 loss 0.05620960518717766\n",
      "38 200 loss 0.04978957772254944\n",
      "38 300 loss 0.05445799231529236\n",
      "38 400 loss 0.05500040203332901\n",
      "test acc :  0.7738\n",
      "39 0 loss 0.04836076498031616\n",
      "39 100 loss 0.055771779268980026\n",
      "39 200 loss 0.04939812421798706\n",
      "39 300 loss 0.05402276664972305\n",
      "39 400 loss 0.05460397154092789\n",
      "test acc :  0.7762\n",
      "40 0 loss 0.04796552658081055\n",
      "40 100 loss 0.055350832641124725\n",
      "40 200 loss 0.04902079701423645\n",
      "40 300 loss 0.05360036343336105\n",
      "40 400 loss 0.054220229387283325\n",
      "test acc :  0.7791\n",
      "41 0 loss 0.04758107289671898\n",
      "41 100 loss 0.0549440011382103\n",
      "41 200 loss 0.04865718260407448\n",
      "41 300 loss 0.053191959857940674\n",
      "41 400 loss 0.05384797602891922\n",
      "test acc :  0.7822\n",
      "42 0 loss 0.047212012112140656\n",
      "42 100 loss 0.0545472726225853\n",
      "42 200 loss 0.048302870243787766\n",
      "42 300 loss 0.05279573053121567\n",
      "42 400 loss 0.05348651856184006\n",
      "test acc :  0.7845\n",
      "43 0 loss 0.04685242474079132\n",
      "43 100 loss 0.054162196815013885\n",
      "43 200 loss 0.047960467636585236\n",
      "43 300 loss 0.05241231992840767\n",
      "43 400 loss 0.05313428118824959\n",
      "test acc :  0.7867\n",
      "44 0 loss 0.0465020090341568\n",
      "44 100 loss 0.053790878504514694\n",
      "44 200 loss 0.04762934893369675\n",
      "44 300 loss 0.05204085633158684\n",
      "44 400 loss 0.05279231071472168\n",
      "test acc :  0.7886\n",
      "45 0 loss 0.04616357758641243\n",
      "45 100 loss 0.053434282541275024\n",
      "45 200 loss 0.047307755798101425\n",
      "45 300 loss 0.051681987941265106\n",
      "45 400 loss 0.05246217921376228\n",
      "test acc :  0.7908\n",
      "46 0 loss 0.045835208147764206\n",
      "46 100 loss 0.05308990553021431\n",
      "46 200 loss 0.04699523746967316\n",
      "46 300 loss 0.05133068561553955\n",
      "46 400 loss 0.05214263126254082\n",
      "test acc :  0.7934\n",
      "47 0 loss 0.04551561921834946\n",
      "47 100 loss 0.05275673791766167\n",
      "47 200 loss 0.04669106751680374\n",
      "47 300 loss 0.050989311188459396\n",
      "47 400 loss 0.05183122679591179\n",
      "test acc :  0.7954\n",
      "48 0 loss 0.04520464316010475\n",
      "48 100 loss 0.05243523046374321\n",
      "48 200 loss 0.0463934987783432\n",
      "48 300 loss 0.0506555549800396\n",
      "48 400 loss 0.05152641981840134\n",
      "test acc :  0.797\n",
      "49 0 loss 0.04490112140774727\n",
      "49 100 loss 0.05212181806564331\n",
      "49 200 loss 0.046104203909635544\n",
      "49 300 loss 0.050329022109508514\n",
      "49 400 loss 0.05123021453619003\n",
      "test acc :  0.7991\n",
      "50 0 loss 0.0446031391620636\n",
      "50 100 loss 0.051818251609802246\n",
      "50 200 loss 0.04582319036126137\n",
      "50 300 loss 0.050009746104478836\n",
      "50 400 loss 0.05093911290168762\n",
      "test acc :  0.8004\n",
      "51 0 loss 0.04431120306253433\n",
      "51 100 loss 0.051523495465517044\n",
      "51 200 loss 0.04554922506213188\n",
      "51 300 loss 0.04969814419746399\n",
      "51 400 loss 0.05065541714429855\n",
      "test acc :  0.8021\n",
      "52 0 loss 0.04402463510632515\n",
      "52 100 loss 0.05123831704258919\n",
      "52 200 loss 0.04528244584798813\n",
      "52 300 loss 0.04939335584640503\n",
      "52 400 loss 0.050379008054733276\n",
      "test acc :  0.8032\n",
      "53 0 loss 0.043743181973695755\n",
      "53 100 loss 0.05095933750271797\n",
      "53 200 loss 0.045021165162324905\n",
      "53 300 loss 0.04909534007310867\n",
      "53 400 loss 0.050108153373003006\n",
      "test acc :  0.8047\n",
      "54 0 loss 0.04347008094191551\n",
      "54 100 loss 0.05068633705377579\n",
      "54 200 loss 0.04476510360836983\n",
      "54 300 loss 0.04880417138338089\n",
      "54 400 loss 0.04984188824892044\n",
      "test acc :  0.8064\n",
      "55 0 loss 0.043203700333833694\n",
      "55 100 loss 0.05042009800672531\n",
      "55 200 loss 0.04451506584882736\n",
      "55 300 loss 0.04851969704031944\n",
      "55 400 loss 0.04958141967654228\n",
      "test acc :  0.8085\n",
      "56 0 loss 0.0429452583193779\n",
      "56 100 loss 0.0501626618206501\n",
      "56 200 loss 0.044269781559705734\n",
      "56 300 loss 0.04824180528521538\n",
      "56 400 loss 0.049327123910188675\n",
      "test acc :  0.8096\n",
      "57 0 loss 0.04269274324178696\n",
      "57 100 loss 0.049908775836229324\n",
      "57 200 loss 0.04403039067983627\n",
      "57 300 loss 0.04796919971704483\n",
      "57 400 loss 0.04907992109656334\n",
      "test acc :  0.8111\n",
      "58 0 loss 0.042445700615644455\n",
      "58 100 loss 0.049658287316560745\n",
      "58 200 loss 0.04379665106534958\n",
      "58 300 loss 0.04770303890109062\n",
      "58 400 loss 0.048837676644325256\n",
      "test acc :  0.813\n",
      "59 0 loss 0.04220323637127876\n",
      "59 100 loss 0.04941178485751152\n",
      "59 200 loss 0.04356915503740311\n",
      "59 300 loss 0.047442320734262466\n",
      "59 400 loss 0.04860005900263786\n",
      "test acc :  0.8145\n",
      "60 0 loss 0.041965849697589874\n",
      "60 100 loss 0.04916984960436821\n",
      "60 200 loss 0.043345287442207336\n",
      "60 300 loss 0.04718870669603348\n",
      "60 400 loss 0.04836668074131012\n",
      "test acc :  0.8164\n",
      "61 0 loss 0.04173411801457405\n",
      "61 100 loss 0.04893278330564499\n",
      "61 200 loss 0.04312619939446449\n",
      "61 300 loss 0.04694286733865738\n",
      "61 400 loss 0.04813831299543381\n",
      "test acc :  0.8188\n",
      "62 0 loss 0.041506774723529816\n",
      "62 100 loss 0.048700422048568726\n",
      "62 200 loss 0.042910367250442505\n",
      "62 300 loss 0.04670284315943718\n",
      "62 400 loss 0.04791618138551712\n",
      "test acc :  0.8197\n",
      "63 0 loss 0.041284989565610886\n",
      "63 100 loss 0.04847363755106926\n",
      "63 200 loss 0.042699359357357025\n",
      "63 300 loss 0.046468932181596756\n",
      "63 400 loss 0.04769790917634964\n",
      "test acc :  0.8206\n",
      "64 0 loss 0.04106815531849861\n",
      "64 100 loss 0.04825229197740555\n",
      "64 200 loss 0.0424925796687603\n",
      "64 300 loss 0.04624093323945999\n",
      "64 400 loss 0.04748294875025749\n",
      "test acc :  0.8214\n",
      "65 0 loss 0.04085569828748703\n",
      "65 100 loss 0.04803464561700821\n",
      "65 200 loss 0.042288888245821\n",
      "65 300 loss 0.046017251908779144\n",
      "65 400 loss 0.047272127121686935\n",
      "test acc :  0.8223\n",
      "66 0 loss 0.04064695164561272\n",
      "66 100 loss 0.047819096595048904\n",
      "66 200 loss 0.04208820313215256\n",
      "66 300 loss 0.045797593891620636\n",
      "66 400 loss 0.04706548526883125\n",
      "test acc :  0.8232\n",
      "67 0 loss 0.04044150561094284\n",
      "67 100 loss 0.04760883003473282\n",
      "67 200 loss 0.04189068451523781\n",
      "67 300 loss 0.045583002269268036\n",
      "67 400 loss 0.046863920986652374\n",
      "test acc :  0.825\n",
      "68 0 loss 0.04024072736501694\n",
      "68 100 loss 0.04740343615412712\n",
      "68 200 loss 0.041696738451719284\n",
      "68 300 loss 0.04537288099527359\n",
      "68 400 loss 0.04666696488857269\n",
      "test acc :  0.8256\n",
      "69 0 loss 0.040043849498033524\n",
      "69 100 loss 0.04720109701156616\n",
      "69 200 loss 0.04150695353746414\n",
      "69 300 loss 0.045166872441768646\n",
      "69 400 loss 0.04647374898195267\n",
      "test acc :  0.8263\n",
      "70 0 loss 0.03984982892870903\n",
      "70 100 loss 0.047002095729112625\n",
      "70 200 loss 0.041320763528347015\n",
      "70 300 loss 0.04496481269598007\n",
      "70 400 loss 0.04628382995724678\n",
      "test acc :  0.8275\n",
      "71 0 loss 0.03965771943330765\n",
      "71 100 loss 0.046806275844573975\n",
      "71 200 loss 0.04113922268152237\n",
      "71 300 loss 0.04476593807339668\n",
      "71 400 loss 0.046097539365291595\n",
      "test acc :  0.8282\n",
      "72 0 loss 0.03946869820356369\n",
      "72 100 loss 0.04661364108324051\n",
      "72 200 loss 0.04096105694770813\n",
      "72 300 loss 0.044569823890924454\n",
      "72 400 loss 0.04591444134712219\n",
      "test acc :  0.8296\n",
      "73 0 loss 0.039283305406570435\n",
      "73 100 loss 0.04642434045672417\n",
      "73 200 loss 0.040784623473882675\n",
      "73 300 loss 0.04437648504972458\n",
      "73 400 loss 0.045734308660030365\n",
      "test acc :  0.8302\n",
      "74 0 loss 0.03910214453935623\n",
      "74 100 loss 0.04623822122812271\n",
      "74 200 loss 0.04061014577746391\n",
      "74 300 loss 0.04418756440281868\n",
      "74 400 loss 0.045556701719760895\n",
      "test acc :  0.8316\n",
      "75 0 loss 0.03892552852630615\n",
      "75 100 loss 0.04605536535382271\n",
      "75 200 loss 0.04043920710682869\n",
      "75 300 loss 0.044002119451761246\n",
      "75 400 loss 0.04538055881857872\n",
      "test acc :  0.8324\n",
      "76 0 loss 0.03875264525413513\n",
      "76 100 loss 0.045875005424022675\n",
      "76 200 loss 0.04027188569307327\n",
      "76 300 loss 0.043820206075906754\n",
      "76 400 loss 0.04520733281970024\n",
      "test acc :  0.8335\n",
      "77 0 loss 0.038582075387239456\n",
      "77 100 loss 0.04569671303033829\n",
      "77 200 loss 0.04010870307683945\n",
      "77 300 loss 0.04364117234945297\n",
      "77 400 loss 0.04503738135099411\n",
      "test acc :  0.8346\n",
      "78 0 loss 0.03841397911310196\n",
      "78 100 loss 0.04552104324102402\n",
      "78 200 loss 0.03994744271039963\n",
      "78 300 loss 0.043464936316013336\n",
      "78 400 loss 0.04486938938498497\n",
      "test acc :  0.8358\n",
      "79 0 loss 0.03824803605675697\n",
      "79 100 loss 0.04534788802266121\n",
      "79 200 loss 0.039787981659173965\n",
      "79 300 loss 0.043291401118040085\n",
      "79 400 loss 0.04470363259315491\n",
      "test acc :  0.8364\n",
      "80 0 loss 0.03808467835187912\n",
      "80 100 loss 0.04517688602209091\n",
      "80 200 loss 0.03963100165128708\n",
      "80 300 loss 0.0431220643222332\n",
      "80 400 loss 0.04453931376338005\n",
      "test acc :  0.8375\n",
      "81 0 loss 0.037923943251371384\n",
      "81 100 loss 0.04500853270292282\n",
      "81 200 loss 0.03947613388299942\n",
      "81 300 loss 0.042955975979566574\n",
      "81 400 loss 0.04437790811061859\n",
      "test acc :  0.8379\n",
      "82 0 loss 0.03776607662439346\n",
      "82 100 loss 0.044842664152383804\n",
      "82 200 loss 0.039324451237916946\n",
      "82 300 loss 0.042791374027729034\n",
      "82 400 loss 0.044217996299266815\n",
      "test acc :  0.8382\n",
      "83 0 loss 0.03761017322540283\n",
      "83 100 loss 0.04467971995472908\n",
      "83 200 loss 0.03917527571320534\n",
      "83 300 loss 0.042628318071365356\n",
      "83 400 loss 0.044059887528419495\n",
      "test acc :  0.8388\n",
      "84 0 loss 0.03745704144239426\n",
      "84 100 loss 0.04451969265937805\n",
      "84 200 loss 0.03902864828705788\n",
      "84 300 loss 0.04246807098388672\n",
      "84 400 loss 0.043904971331357956\n",
      "test acc :  0.8397\n",
      "85 0 loss 0.03730637580156326\n",
      "85 100 loss 0.04436231404542923\n",
      "85 200 loss 0.038883477449417114\n",
      "85 300 loss 0.04231100529432297\n",
      "85 400 loss 0.04375187307596207\n",
      "test acc :  0.8412\n",
      "86 0 loss 0.03715896978974342\n",
      "86 100 loss 0.04420659691095352\n",
      "86 200 loss 0.03874034434556961\n",
      "86 300 loss 0.042156580835580826\n",
      "86 400 loss 0.04360025376081467\n",
      "test acc :  0.8421\n",
      "87 0 loss 0.037014275789260864\n",
      "87 100 loss 0.044052623212337494\n",
      "87 200 loss 0.03859835863113403\n",
      "87 300 loss 0.04200438782572746\n",
      "87 400 loss 0.0434495247900486\n",
      "test acc :  0.8428\n",
      "88 0 loss 0.03687151521444321\n",
      "88 100 loss 0.043899957090616226\n",
      "88 200 loss 0.03845846652984619\n",
      "88 300 loss 0.041854195296764374\n",
      "88 400 loss 0.04330062493681908\n",
      "test acc :  0.8436\n",
      "89 0 loss 0.036731164902448654\n",
      "89 100 loss 0.04374951124191284\n",
      "89 200 loss 0.03832138702273369\n",
      "89 300 loss 0.04170690476894379\n",
      "89 400 loss 0.04315396025776863\n",
      "test acc :  0.844\n",
      "90 0 loss 0.036591917276382446\n",
      "90 100 loss 0.043600987643003464\n",
      "90 200 loss 0.03818712383508682\n",
      "90 300 loss 0.041561465710401535\n",
      "90 400 loss 0.04300937056541443\n",
      "test acc :  0.8452\n",
      "91 0 loss 0.03645489737391472\n",
      "91 100 loss 0.04345426708459854\n",
      "91 200 loss 0.038055308163166046\n",
      "91 300 loss 0.041418105363845825\n",
      "91 400 loss 0.04286690801382065\n",
      "test acc :  0.8457\n",
      "92 0 loss 0.036319632083177567\n",
      "92 100 loss 0.04330841824412346\n",
      "92 200 loss 0.03792550414800644\n",
      "92 300 loss 0.04127715900540352\n",
      "92 400 loss 0.04272657632827759\n",
      "test acc :  0.8471\n",
      "93 0 loss 0.036186523735523224\n",
      "93 100 loss 0.04316403344273567\n",
      "93 200 loss 0.03779716417193413\n",
      "93 300 loss 0.04113849624991417\n",
      "93 400 loss 0.04258804768323898\n",
      "test acc :  0.8483\n",
      "94 0 loss 0.036055319011211395\n",
      "94 100 loss 0.043021492660045624\n",
      "94 200 loss 0.037670254707336426\n",
      "94 300 loss 0.041001882404088974\n",
      "94 400 loss 0.04245080426335335\n",
      "test acc :  0.8492\n",
      "95 0 loss 0.03592623397707939\n",
      "95 100 loss 0.04288052022457123\n",
      "95 200 loss 0.03754490613937378\n",
      "95 300 loss 0.04086753726005554\n",
      "95 400 loss 0.042315687984228134\n",
      "test acc :  0.8498\n",
      "96 0 loss 0.03579932451248169\n",
      "96 100 loss 0.04274066537618637\n",
      "96 200 loss 0.03742077201604843\n",
      "96 300 loss 0.040735382586717606\n",
      "96 400 loss 0.04218202829360962\n",
      "test acc :  0.8505\n",
      "97 0 loss 0.03567362204194069\n",
      "97 100 loss 0.042602285742759705\n",
      "97 200 loss 0.0372978039085865\n",
      "97 300 loss 0.0406050905585289\n",
      "97 400 loss 0.04204951971769333\n",
      "test acc :  0.8515\n",
      "98 0 loss 0.03555028885602951\n",
      "98 100 loss 0.0424656942486763\n",
      "98 200 loss 0.03717616945505142\n",
      "98 300 loss 0.04047643020749092\n",
      "98 400 loss 0.04191843792796135\n",
      "test acc :  0.8523\n",
      "99 0 loss 0.035428889095783234\n",
      "99 100 loss 0.042330287396907806\n",
      "99 200 loss 0.03705455735325813\n",
      "99 300 loss 0.04034944623708725\n",
      "99 400 loss 0.04178903251886368\n",
      "test acc :  0.8531\n"
     ]
    }
   ],
   "source": [
    "# 数据集加载\n",
    "# keras.datasets\n",
    "# tf.data.Dataset.from_tensor_sclices : shuffle, map, batch, repeat\n",
    "# input pipeline\n",
    "# such as : boston housing, mnist/fashion mnist, cifar10/100, imdb\n",
    "\n",
    "# 前向传播 forward\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# loading data\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# convert to Tensor\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "# show the info\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the dataset and split the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)\n",
    "\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print(\"batch\", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 权值\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "# tf.Variable 才会自动记录梯度信息，tf.Tensor 不会记录梯度信息，故此值为 None，类型为 NoneType\n",
    "# 需要给一个好点的初始值，否则容易 loss 爆炸，出现 nan(not a number) 情况,stddev=0.1 方差给小一点\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 学习率 ，步长 10^-3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 对数据集迭代 100 次\n",
    "# for epoch in range(10): # test acc = 0.5566\n",
    "for epoch in range(100): # test acc = 0.8531\n",
    "    # 对数据集一次循环\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x [128, 28, 28]\n",
    "        # y [128]\n",
    "        # 进行维度转换 [128, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])   \n",
    "    \n",
    "        # 自动求导过程,梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            # x [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            # 添加非线性，relu 激活函数\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 +b3\n",
    "        \n",
    "            # compute loss\n",
    "            # out [b, 10]\n",
    "            # y [b] => [b, 10]\n",
    "            y_one_hot = tf.one_hot(y, depth=10)\n",
    "        \n",
    "            # MSE = mean((y - out)**2)\n",
    "            loss = tf.square(y_one_hot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "    \n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # 原地更新，否则就返回 tf.Tensor 类型了，无法进行下一个梯度更新\n",
    "        # w1 = w1 - learning_rate * grads[0]\n",
    "        w1.assign_sub(learning_rate * grads[0])\n",
    "        b1.assign_sub(learning_rate * grads[1])\n",
    "        w2.assign_sub(learning_rate * grads[2])\n",
    "        b2.assign_sub(learning_rate * grads[3])\n",
    "        w3.assign_sub(learning_rate * grads[4])\n",
    "        b3.assign_sub(learning_rate * grads[5])\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, \"loss\", float(loss))\n",
    "    \n",
    "    # test/evluation\n",
    "    total_correct, total_num = 0, 0\n",
    "    for step, (x, y) in enumerate(test_db):\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        \n",
    "        h1 = tf.nn.relu(x@w1 + b1)\n",
    "        h2 = tf.nn.relu(h1@w2 + b2)        \n",
    "        out = h2@w3 + b3\n",
    "        \n",
    "        prob = tf.nn.softmax(out, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        \n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "        \n",
    "    acc = total_correct / total_num\n",
    "    print(\"test acc : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  8         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  6         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense/kernel:0 (3, 2)\n",
      "dense/bias:0 (2,)\n",
      "dense_1/kernel:0 (2, 2)\n",
      "dense_1/bias:0 (2,)\n",
      "dense_2/kernel:0 (2, 2)\n",
      "dense_2/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "# 全连接层\n",
    "# matmul\n",
    "# neural network\n",
    "# deep learning\n",
    "# multi-layer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "x = tf.random.normal([2, 3])\n",
    "\n",
    "model = keras.Sequential([\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(2)]) # 没有加 relu 非线性的这一层，称之为 logits\n",
    "\n",
    "model.build(input_shape=[None, 3])\n",
    "model.summary()\n",
    "\n",
    "for p in model.trainable_variables:\n",
    "    print(p.name, p.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出方式\n",
    "# such as : R 整个实数集，[0-1]输出概率值，[0-1]&所有概率和为1，[-1-1]范围\n",
    "# tf.sigmoid => [0-1] => sigmoid 激活函数以及压缩\n",
    "# tf.nn.softmax => [0-1]&所有概率之和为 1 => softmax 函数\n",
    "# tf.tanh => [-1 -1] => 通过 sigmoid 函数扩大到 [0-2],然后平移到 [-1 -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "# MSE\n",
    "# Cross Entropy Loss 熵 交叉熵 散度\n",
    "# Hinge Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 梯度下降\n",
    "# gradient descent\n",
    "# auto gradient\n",
    "# with tf.GradientTape() as tape:\n",
    "# 二阶求导  2nd-order\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "# 二阶求导\n",
    "with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2:\n",
    "        y = x * w + b\n",
    "    dy_dw, dy_db = tape2.gradient(y, [w, b])\n",
    "d2y_dw2 = tape1.gradient(dy_dw, w)\n",
    "\n",
    "print(dy_dw)\n",
    "print(dy_db)\n",
    "print(d2y_dw2)\n",
    "\n",
    "assert dy_dw.numpy() == 3.0\n",
    "assert d2y_dw2 is None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.03023818]\n",
      " [-0.04783473]\n",
      " [ 0.2962501 ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor([-0.25907284], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# activation functions 激活函数\n",
    "# 激活函数及其梯度\n",
    "# 温水煮青蛙\n",
    "# sigmoid logistic\n",
    "\n",
    "# loss及其梯度\n",
    "# softmax\n",
    "\n",
    "# 单输出感知器模型及其梯度\n",
    "# Single-output Perceptron\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.normal([1, 3])\n",
    "w = tf.ones([3, 1])\n",
    "b = tf.ones([1])\n",
    "y = tf.constant([1])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    logits = tf.sigmoid(x@w +b)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(y, logits))\n",
    "    \n",
    "grads = tape.gradient(loss, [w, b])\n",
    "print(grads[0])\n",
    "print(grads[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.00572357  0.00910154 -0.00337799]\n",
      " [-0.00269983  0.02833442 -0.0256346 ]\n",
      " [ 0.00435749 -0.18683618  0.18247873]\n",
      " [-0.00581362  0.02845965 -0.02264604]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor([-0.00692527  0.05489153 -0.04796629], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 多输出感知器模型及其梯度\n",
    "# Multi-output Perceptron\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.normal([2, 4])\n",
    "w = tf.random.normal([4, 3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2, 0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    prob = tf.nn.softmax(x@w + b, axis=1)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(tf.one_hot(y, depth=3), prob))\n",
    "    \n",
    "grads = tape.gradient(loss, [w, b])\n",
    "print(grads[0])\n",
    "print(grads[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y range:  (120,) (120,)\n",
      "X, Y maps:  (120, 120) (120, 120)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: x = [ 3.26       -0.09999999], f(x) = 34.0\n",
      "step 20: x = [ 3.54679   -1.4388103], f(x) = 2.747403860092163\n",
      "step 40: x = [ 3.5843565 -1.8473401], f(x) = 1.7569736883160658e-05\n",
      "step 60: x = [ 3.5844283 -1.8481257], f(x) = 2.3646862246096134e-11\n",
      "step 80: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n",
      "step 100: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n",
      "step 120: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n",
      "step 140: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n",
      "step 160: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n",
      "step 180: x = [ 3.5844283 -1.8481264], f(x) = 2.2737367544323206e-13\n"
     ]
    }
   ],
   "source": [
    "# 链式法则\n",
    "# chain rule\n",
    "# 神经网络层 权值不断更新\n",
    "\n",
    "# 多层感知器 \n",
    "# Multi-Layer Perceptron\n",
    "# 反向传播算法\n",
    "\n",
    "# Himmelblau 函数优化\n",
    "# f(x, y) = (x**2 + y - 11)**2 + (x + y**2 -7)**2\n",
    "# Himmelblau function 常用于测试算法模型\n",
    "# Himmelblau 方程，是科学家们研究出来专门用于检测一个优化器效果的方程\n",
    "# 四个点（最小值）精确解\n",
    "# f(3.0, 2.0) = 0.0; f(-2.805118, 3.131312) = 0.0; f(-3.779310, -3.283186) = 0.0; f(3.584428, -1.848126) = 0.0; \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# This is important for 3d plotting \n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "def himmelblau(x):\n",
    "    return (x[0] **2 + x[1] - 11) **2 + (x[0] + x[1] **2 - 7) **2\n",
    "\n",
    "x = np.arange(-6, 6, 0.1)\n",
    "y = np.arange(-6, 6, 0.1)\n",
    "print(\"x, y range: \", x.shape, y.shape)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "print(\"X, Y maps: \", X.shape, Y.shape)\n",
    "Z = himmelblau([X, Y])\n",
    "\n",
    "# 可视化 himmelblau 函数\n",
    "fig = plt.figure(\"himmelblau\")\n",
    "# ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, Z)\n",
    "ax.view_init(60, -30)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# gradient descent\n",
    "# 初始点位置\n",
    "# x = tf.constant([-4., 0.])\n",
    "x = tf.constant([4., 0.])\n",
    "\n",
    "for step in range(200):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([x])\n",
    "        y = himmelblau(x)\n",
    "        \n",
    "    grads = tape.gradient(y, [x])[0]\n",
    "    x -= 0.01 * grads\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(\"step {}: x = {}, f(x) = {}\".format(step, x.numpy(), y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "batch:  (128, 28, 28) (128,)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0  loss:  2.3147687911987305 0.19546884298324585\n",
      "0 100  loss:  0.6002034544944763 16.171077728271484\n",
      "0 200  loss:  0.467648983001709 16.48202133178711\n",
      "0 300  loss:  0.4906914234161377 18.411293029785156\n",
      "0 400  loss:  0.38509050011634827 20.211084365844727\n",
      "0 test acc :  0.8519\n",
      "1 0  loss:  0.2830538749694824 20.031679153442383\n",
      "1 100  loss:  0.46995460987091064 19.620086669921875\n",
      "1 200  loss:  0.3051767349243164 23.614288330078125\n",
      "1 300  loss:  0.37085139751434326 23.230236053466797\n",
      "1 400  loss:  0.40304991602897644 22.69931411743164\n",
      "1 test acc :  0.8554\n",
      "2 0  loss:  0.4802855849266052 24.141891479492188\n",
      "2 100  loss:  0.2845393419265747 19.173513412475586\n",
      "2 200  loss:  0.267355352640152 21.797412872314453\n",
      "2 300  loss:  0.2565942704677582 26.85940170288086\n",
      "2 400  loss:  0.320268839597702 25.372966766357422\n",
      "2 test acc :  0.8682\n",
      "3 0  loss:  0.33387959003448486 31.086746215820312\n",
      "3 100  loss:  0.36249840259552 28.67864227294922\n",
      "3 200  loss:  0.4090268015861511 29.302160263061523\n",
      "3 300  loss:  0.330291211605072 32.58943557739258\n",
      "3 400  loss:  0.3299080729484558 37.38407897949219\n",
      "3 test acc :  0.8726\n",
      "4 0  loss:  0.342499703168869 30.403961181640625\n",
      "4 100  loss:  0.22298598289489746 40.17292785644531\n",
      "4 200  loss:  0.27668896317481995 36.07453918457031\n",
      "4 300  loss:  0.33142924308776855 39.401424407958984\n",
      "4 400  loss:  0.402438759803772 38.788963317871094\n",
      "4 test acc :  0.8757\n",
      "5 0  loss:  0.281987726688385 42.032020568847656\n",
      "5 100  loss:  0.28246861696243286 38.307952880859375\n",
      "5 200  loss:  0.2812153697013855 37.36005401611328\n",
      "5 300  loss:  0.21311286091804504 41.64207458496094\n",
      "5 400  loss:  0.3277242183685303 44.99666213989258\n",
      "5 test acc :  0.8794\n",
      "6 0  loss:  0.18479685485363007 38.16828918457031\n",
      "6 100  loss:  0.2853056788444519 41.96675109863281\n",
      "6 200  loss:  0.34014442563056946 48.767723083496094\n",
      "6 300  loss:  0.2087569534778595 44.6828727722168\n",
      "6 400  loss:  0.31266531348228455 45.168861389160156\n",
      "6 test acc :  0.8836\n",
      "7 0  loss:  0.18512266874313354 51.207366943359375\n",
      "7 100  loss:  0.2407016158103943 48.068115234375\n",
      "7 200  loss:  0.23010295629501343 43.07957077026367\n",
      "7 300  loss:  0.27204322814941406 52.998863220214844\n",
      "7 400  loss:  0.23936548829078674 45.65752410888672\n",
      "7 test acc :  0.8784\n",
      "8 0  loss:  0.2029229700565338 46.812625885009766\n",
      "8 100  loss:  0.2596505284309387 53.95172882080078\n",
      "8 200  loss:  0.24548420310020447 52.789451599121094\n",
      "8 300  loss:  0.29390668869018555 56.47236633300781\n",
      "8 400  loss:  0.3244130313396454 55.62638854980469\n",
      "8 test acc :  0.8838\n",
      "9 0  loss:  0.2050458788871765 48.471893310546875\n",
      "9 100  loss:  0.2473633587360382 47.626014709472656\n",
      "9 200  loss:  0.2136945128440857 51.85163116455078\n",
      "9 300  loss:  0.2409866601228714 60.38726043701172\n",
      "9 400  loss:  0.30041325092315674 55.493019104003906\n",
      "9 test acc :  0.8796\n"
     ]
    }
   ],
   "source": [
    "# Fashion MNIST\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "# data processing 数据预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "    \n",
    "# loading dataset\n",
    "(x, y), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# 数据预处理 映射函数即可\n",
    "db_train = db_train.map(preprocess)\n",
    "# shuffle and batch 操作\n",
    "batch_size = 128\n",
    "db_train = db_train.shuffle(10000).batch(batch_size)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "# 数据预处理 映射函数即可\n",
    "db_test = db_test.map(preprocess)\n",
    "# shuffle and batch 操作\n",
    "db_test = db_test.shuffle(10000).batch(batch_size)\n",
    "\n",
    "# sample 操作\n",
    "db_train_iter = iter(db_train)\n",
    "sample = next(db_train_iter)\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 神经网络层构建\n",
    "model = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "model.build(input_shape=[None, 28*28])\n",
    "model.summary()\n",
    "\n",
    "# 优化器 learning_rate\n",
    "# w = w - lrarning_rete * gradient\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "\n",
    "def main():\n",
    "    # 对数据集循环训练多少次 epoch\n",
    "    for epoch in range(10):\n",
    "        # 对每个 batch 循环训练\n",
    "        for step, (x, y) in enumerate(db_train):\n",
    "            # 维度转换\n",
    "            # x: [b, 28, 28] => [b, 784]\n",
    "            # y: [b]\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # 跟踪梯度信息，自动求导\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 784] => [b, 10]\n",
    "                logits = model(x)\n",
    "                # compute loss\n",
    "                y_one_hot = tf.one_hot(y, depth=10)\n",
    "                # [b]\n",
    "                loss_mse = tf.reduce_mean(tf.losses.MSE(y_one_hot, logits))\n",
    "                loss_ce = tf.losses.categorical_crossentropy(y_one_hot, logits, from_logits=True)\n",
    "                loss_ce = tf.reduce_mean(loss_ce)\n",
    "            \n",
    "            # 获取梯度\n",
    "            grads = tape.gradient(loss_ce, model.trainable_variables)\n",
    "            # grads = tape.gradient(loss_mse, model.trainable_variables)\n",
    "            # 更新梯度\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "            # 每 100 次训练后查看 loss\n",
    "            if step % 100 == 0:\n",
    "                print(epoch, step, \" loss: \", float(loss_ce), float(loss_mse))\n",
    "        \n",
    "        # test\n",
    "        # 统计正确个数\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for x, y in db_test:\n",
    "            # 维度变换\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # [b, 10]\n",
    "            logits = model(x)\n",
    "            # 计算概率最大的位置索引\n",
    "            # logits => prob,  [b, 10]\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            # [b, 10] => [b] pred\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # 不需要 one_hot 编码\n",
    "            # correct : [b], True: equal; False: not equal\n",
    "            correct = tf.equal(pred, y)\n",
    "            # 将 bool 转换为 int （1或者0）\n",
    "            correct = tf.cast(correct, dtype=tf.int32)\n",
    "            # 计算正确个数\n",
    "            correct = tf.reduce_sum(correct)\n",
    "            \n",
    "            total_correct += int(correct)\n",
    "            total_num += x.shape[0]\n",
    "            \n",
    "        # compute the accurate\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, \"test acc : \", acc)\n",
    "            \n",
    "\n",
    "# if __name__ == \" __main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:  (60000, 28, 28) (60000,) <built-in method min of numpy.ndarray object at 0x000000000F5F4E90> <built-in method max of numpy.ndarray object at 0x000000000F5F4EE0>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0  loss:  2.321824550628662\n",
      "0 Evaluate Acc :  0.09575320512820513\n",
      "100  loss:  0.2881273031234741\n",
      "200  loss:  0.17710977792739868\n",
      "300  loss:  0.26295536756515503\n",
      "400  loss:  0.17406576871871948\n",
      "500  loss:  0.07845563441514969\n",
      "500 Evaluate Acc :  0.9586338141025641\n",
      "600  loss:  0.06429676711559296\n",
      "700  loss:  0.16216646134853363\n",
      "800  loss:  0.07987567782402039\n",
      "900  loss:  0.1479039490222931\n",
      "1000  loss:  0.06953258812427521\n",
      "1000 Evaluate Acc :  0.9657451923076923\n",
      "1100  loss:  0.2262805849313736\n",
      "1200  loss:  0.080322265625\n",
      "1300  loss:  0.06649616360664368\n",
      "1400  loss:  0.11841060221195221\n",
      "1500  loss:  0.04989156126976013\n",
      "1500 Evaluate Acc :  0.9696514423076923\n",
      "1600  loss:  0.04563354700803757\n",
      "1700  loss:  0.060657136142253876\n",
      "1800  loss:  0.10466103255748749\n",
      "1900  loss:  0.03204208239912987\n",
      "2000  loss:  0.07820688933134079\n",
      "2000 Evaluate Acc :  0.9644431089743589\n",
      "2100  loss:  0.09313135594129562\n",
      "2200  loss:  0.018842974677681923\n",
      "2300  loss:  0.035334981977939606\n",
      "2400  loss:  0.07068389654159546\n",
      "2500  loss:  0.10856356471776962\n",
      "2500 Evaluate Acc :  0.9689503205128205\n",
      "2600  loss:  0.037488311529159546\n",
      "2700  loss:  0.07839369773864746\n",
      "2800  loss:  0.08898462355136871\n",
      "2900  loss:  0.10911071300506592\n",
      "3000  loss:  0.017549464479088783\n",
      "3000 Evaluate Acc :  0.9719551282051282\n",
      "3100  loss:  0.07895295321941376\n",
      "3200  loss:  0.05205662176012993\n",
      "3300  loss:  0.08300615847110748\n",
      "3400  loss:  0.06607582420110703\n",
      "3500  loss:  0.010589923709630966\n",
      "3500 Evaluate Acc :  0.9587339743589743\n",
      "3600  loss:  0.07947620749473572\n",
      "3700  loss:  0.14526647329330444\n",
      "3800  loss:  0.06118522584438324\n",
      "3900  loss:  0.06425407528877258\n",
      "4000  loss:  0.1705816686153412\n",
      "4000 Evaluate Acc :  0.9684495192307693\n",
      "4100  loss:  0.06243268400430679\n",
      "4200  loss:  0.060158517211675644\n",
      "4300  loss:  0.12400893121957779\n",
      "4400  loss:  0.05779305472970009\n",
      "4500  loss:  0.027019605040550232\n",
      "4500 Evaluate Acc :  0.9729567307692307\n",
      "4600  loss:  0.051652222871780396\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 可视化 Tensor 在数据流中 flow 过程\n",
    "# Visdom 可视化\n",
    "# 监控数据流 TensorBoard\n",
    "# tensorboard 会监听磁盘数据变换，使用 web UI 界面展示出来\n",
    "# 1、installation 2、curves 3、image visualization\n",
    "# principle：1、listen logdir 2、build summary instance 3、fed data into summary instance\n",
    "# steps：\n",
    "# step 1、run listener：cmd; cd logdir; tensorboard --logdir logs; web site:6006\n",
    "# step 2、buld summary: 代码中实现 \n",
    "# =================================================================\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# log_dir = \"logs\" + current_time\n",
    "# summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "# =================================================================\n",
    "# step 3、feed scalar: 代码中实现 \n",
    "# =================================================================\n",
    "# wtih summary_writer.as_default():\n",
    "#     tf.summary.scalar(\"loss\", float(loss), step=epoch)\n",
    "#     tf.summary.scalar(\"accuracy\", float(train_accuracy), step=epoch)\n",
    "# =================================================================\n",
    "# step 4、feed single image or multi-images: 代码中实现\n",
    "# \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io\n",
    "\n",
    "# data processing 数据预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "# plot figure to image PNG\n",
    "def plot_to_image(figure):\n",
    "    # convert the matplotlib plot specified by 'figure' to a PNG image and return it.\n",
    "    # the supplied figure is closed and inaccessible after the call.\n",
    "    \n",
    "    # save the plot to a PNG in memory\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # closing the figure prevents it from being dispalyed directly inside\n",
    "    # the notebook\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# fed multi-images\n",
    "def image_grid(images):\n",
    "    # return a 5X5 grid of the MNIST images as a matplotlib figure.\n",
    "    \n",
    "    # create a figure to contain the plot\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        # start next subplot\n",
    "        plt.subplot(5, 5, i + 1, title=\"name\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "    \n",
    "    return figure\n",
    "\n",
    "# batch\n",
    "batch_size = 128\n",
    "# loading dataset\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print(\"datasets: \", x.shape, y.shape, x.min, y.max)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# 数据预处理 映射函数即可  shuffle and batch 操作\n",
    "db = db.map(preprocess).shuffle(60000).batch(batch_size).repeat(10)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "# 数据预处理 映射函数即可  shuffle and batch 操作\n",
    "ds_val = ds_val.map(preprocess).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# 神经网络层构建 5 layers\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "network.build(input_shape=[None, 28*28])\n",
    "network.summary()\n",
    "\n",
    "# 优化器 learning_rate\n",
    "# w = w - lrarning_rete * gradient\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "# TensorBoard 可视化操作步骤，监听磁盘路径\n",
    "# logs/ 文件夹 与该程序文件是同级\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/\" + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# get x from (x, y)\n",
    "sample_img = next(iter(db))[0]\n",
    "\n",
    "# get first image instance\n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "\n",
    "# TensorBoard 可视化操作步骤，写入数据 image\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample : \", sample_img, step=0)\n",
    "    \n",
    "\n",
    "# \n",
    "# 对每个 batch 循环训练\n",
    "for step, (x, y) in enumerate(db):\n",
    "    # 跟踪梯度信息，自动求导\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 维度转换\n",
    "        # x: [b, 28, 28] => [b, 784]\n",
    "        # y: [b]\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # compute loss\n",
    "        y_one_hot = tf.one_hot(y, depth=10)\n",
    "        # [b]\n",
    "        # loss_mse = tf.reduce_mean(tf.losses.MSE(y_one_hot, logits))\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True))\n",
    "            \n",
    "    # 获取梯度\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    # grads = tape.gradient(loss_mse, network.trainable_variables)\n",
    "    # 更新梯度\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "            \n",
    "    # 每 100 次训练后查看 loss\n",
    "    if step % 100 == 0:\n",
    "        print(step, \" loss: \", float(loss))\n",
    "        # TensorBoard 可视化操作步骤，写入数据 loss\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"train-loss : \", float(loss), step=step)\n",
    "        \n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        for _, (x, y) in enumerate(ds_val):\n",
    "            # 维度变换\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # [b, 10]\n",
    "            out = network(x)\n",
    "            # 计算概率最大的位置索引\n",
    "            # out => prob,  [b, 10]\n",
    "            # prob = tf.nn.softmax(out, axis=1)\n",
    "            # [b, 10] => [b] pred\n",
    "            pred = tf.argmax(out, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # 不需要 one_hot 编码\n",
    "            # correct : [b], True: equal; False: not equal\n",
    "            correct = tf.equal(pred, y)\n",
    "            # 将 bool tensor 转换为 int tensor （1或者0） 转换为 numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "            \n",
    "        # compute the accurate\n",
    "        print(step, \"Evaluate Acc : \", total_correct / total)\n",
    "        \n",
    "        # TensorBoard 可视化操作步骤，写入数据 loss and images\n",
    "        # print(x.shape)\n",
    "        val_images = x[:25]\n",
    "        val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"test-acc\", float(total_correct / total), step=step)\n",
    "            tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "            val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "            figure = image_grid(val_images)\n",
    "            tf.summary.image(\"val-images\", plot_to_image(figure), step=step)\n",
    "            \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 高层接口API 优化并且简化常规的方法代码（集成为接口 API）\n",
    "# 此处 keras 是 TensorFlow 集成的 tf.keras，而不是真正实际上讲的 Keras Keras != tf.keras\n",
    "# API: datasets, layers, losses, metrics, optimizers\n",
    "# from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "# metrics 提供计算记录清空等等一系列关于 metrics 的操作\n",
    "# compile & fit ：Compile => Fit => Evaluate => Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:  (60000, 28, 28) (60000,) <built-in method min of numpy.ndarray object at 0x000000001271FDF0> <built-in method max of numpy.ndarray object at 0x000000001271FEE0>\n",
      "(128, 784) (128, 10)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.2685 - accuracy: 0.9204\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.1505 - val_accuracy: 0.9599\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.1121 - accuracy: 0.9689\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0982 - accuracy: 0.9742 - val_loss: 0.1212 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0931 - accuracy: 0.9756\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.1085 - accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "# 自定义网络 (可以连接全连接层网络) 实现自己的逻辑需求\n",
    "# keras.Sequential\n",
    "# keras.layers.Layer\n",
    "# keras.Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print(\"datasets: \", x.shape, y.shape, x.min, y.max)\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "network.build(input_shape=[None, 28*28])\n",
    "network.summary()\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    # 自定义层\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable(\"w\", [inp_dim, outp_dim])\n",
    "        self.bias = self.add_variable(\"b\", [outp_dim])\n",
    "        \n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "        out = inputs @ self.kernel + self.bias\n",
    "        return out\n",
    "\n",
    "# 自定义网络模型\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = MyDense(28*28, 256)\n",
    "        self.fc2 = MyDense(256, 128)        \n",
    "        self.fc3 = MyDense(128, 64)        \n",
    "        self.fc4 = MyDense(64, 32)        \n",
    "        self.fc5 = MyDense(32, 10)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc2(x)        \n",
    "        x = tf.nn.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc4(x)        \n",
    "        x = tf.nn.relu(x)       \n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "#\n",
    "network = MyModel()\n",
    "\n",
    "network.compile(optimizer = optimizers.Adam(lr=0.01),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.fit(db, epochs=5, validation_data=ds_val, validation_freq=2)\n",
    "\n",
    "network.evaluate(ds_val)\n",
    "\n",
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "pred = network.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的保存和加载\n",
    "# save/load weights\n",
    "#==================================================\n",
    "# # save the weights\n",
    "# model.save_weights(\"./checkpoints/my_checkpoint\")\n",
    "# # restore the weights\n",
    "# model = create_model()\n",
    "# model.load_weights(\"./checkpoints/my_checkpoint\")\n",
    "#==================================================\n",
    "# save/load entire model\n",
    "#==================================================\n",
    "# # save entire model\n",
    "# network.save(\"model.h5\")\n",
    "# # load entire model\n",
    "# network = tf.keras.models.load_model(\"model.h5\")\n",
    "#==================================================\n",
    "# saved_model\n",
    "#==================================================\n",
    "# # 工业部署环境\n",
    "# tf.saved_model.save(m, \"./tmp/saved_model/\")\n",
    "# # 加载 loading\n",
    "# imported = tf.saved_model.load(path)\n",
    "# f = imported.signatures[\"serving_default\"]\n",
    "#==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce so we will re-download the data.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "   106496/170498071 [..............................] - ETA: 51:52:29"
     ]
    }
   ],
   "source": [
    "# CIFAR10 datasets\n",
    "# 自定义网络实战\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0-255] => [-1 -1]\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "# [32, 32, 3]\n",
    "(x, y), (x_val, y_val) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y)\n",
    "y_val = tf.squeeze(y_val)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "y_val = tf.one_hot(y_val, depth=10)\n",
    "print(\"datasets: \", x.shape, y.shape, x_val.shape, y_val.shape, x.min, y.max)\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "test_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "test_val = test_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    # to replace standard layers.Dense()\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable(\"w\", [inp_dim, outp_dim])\n",
    "        # self.bias = self.add_variable(\"b\", [outp_dim])\n",
    "        \n",
    "    #\n",
    "    def call(self, imputs, training=None):\n",
    "        # x = inputs @ self.kernel + self.bias\n",
    "        x = inputs @ self.kernel\n",
    "        return x\n",
    "\n",
    "# 自定义网络模型\n",
    "class MyNetwork(keras.Model):\n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = MyDense(32*32*3, 256)\n",
    "        self.fc2 = MyDense(256, 128)        \n",
    "        self.fc3 = MyDense(128, 64)        \n",
    "        self.fc4 = MyDense(64, 32)        \n",
    "        self.fc5 = MyDense(32, 10)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        # \n",
    "        x = tf.reshape(inputs, [-1, 32*32*3])\n",
    "        x = self.fc1(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc2(x)        \n",
    "        x = tf.nn.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc4(x)        \n",
    "        x = tf.nn.relu(x)       \n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer = optimizers.Adam(lr=1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.fit(db, epochs=15, validation_data=test_db, validation_freq=1)\n",
    "network.evaluate(test_val)\n",
    "\n",
    "# 模型权重保存\n",
    "network.save_weights(\"ckpt/weights.ckpt\")\n",
    "del network\n",
    "print(\"saved to ckpt/weights.ckpt\")\n",
    "\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer = optimizers.Adam(lr=1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "# 模型权重加载\n",
    "network.load_weights(\"ckpt/weights.ckpt\")\n",
    "print(\"loaded weights from file.\")\n",
    "network.evaluate(test_val)\n",
    "\n",
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "pred = network.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
