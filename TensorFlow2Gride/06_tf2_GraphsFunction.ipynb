{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earned-instrument",
   "metadata": {},
   "source": [
    "# Introduction to graphs and tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-fifty",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "raw",
   "id": "committed-melbourne",
   "metadata": {},
   "source": [
    "This guide goes beneath the surface of TensorFlow and Keras to see how TensorFlow works. If you instead want to immediately get started with Keras, please see our collection of Keras guides.\n",
    "\n",
    "In this guide you'll see the core of how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "worth-annotation",
   "metadata": {},
   "source": [
    "Note: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "speaking-dryer",
   "metadata": {},
   "source": [
    "This is a big-picture overview that covers how tf.function allows you to switch from eager execution to graph execution. For a more complete specification of tf.function, see the tf.function guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-communication",
   "metadata": {},
   "source": [
    "### i. What are graphs?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "express-providence",
   "metadata": {},
   "source": [
    "In the previous three guides, you have seen TensorFlow running eagerly. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
    "\n",
    "While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. Graph execution means that tensor computations are executed as a TensorFlow graph, sometimes referred to as a tf.Graph or simply a \"graph.\"\n",
    "\n",
    "Graphs are data structures that contain a set of tf.Operation objects, which represent units of computation; and tf.Tensor objects, which represent the units of data that flow between operations. They are defined in a tf.Graph context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-aggregate",
   "metadata": {},
   "source": [
    "### ii. The benefits of graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "blind-venice",
   "metadata": {},
   "source": [
    "With a graph, you have a great deal of flexibility. You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for saved models when it exports them from Python.\n",
    "\n",
    "Graphs are also easily optimized, allowing the compiler to do transformations like:\n",
    "\n",
    "- Statically infer the value of tensors by folding constant nodes in your computation (\"constant folding\").\n",
    "- Separate sub-parts of a computation that are independent and split them between threads or devices.\n",
    "- Simplify arithmetic operations by eliminating common subexpressions.\n",
    "- There is an entire optimization system, Grappler, to perform this and other speedups.\n",
    "\n",
    "In short, graphs are extremely useful and let your TensorFlow run fast, run in parallel, and run efficiently on multiple devices.\n",
    "\n",
    "However, you still want to define our machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-thriller",
   "metadata": {},
   "source": [
    "## 2. Taking advantage of graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "perfect-nickel",
   "metadata": {},
   "source": [
    "You create and run a graph in TensorFlow by using tf.function, either as a direct call or as a decorator. tf.function takes a regular function as input and returns a Function. A Function is a Python callable that builds TensorFlow graphs from the Python function. You use a Function in the same way as its Python equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of Tensorflow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"The version of Tensorflow: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "judicial-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `Function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "suspected-penetration",
   "metadata": {},
   "source": [
    "On the outside, a Function looks like a regular function you write using TensorFlow operations. Underneath, however, it is very different. A Function encapsulates several tf.Graphs behind one API. That is how Function is able to give you the benefits of graph execution, like speed and deployability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "physical-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.function applies to a function and all other functions it calls:\n",
    "\n",
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator to make `outer_function` a `Function`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "documentary-maker",
   "metadata": {},
   "source": [
    "If you have used TensorFlow 1.x, you will notice that at no time did you need to define a Placeholder or tf.Session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-component",
   "metadata": {},
   "source": [
    "### i. Converting Python functions to graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "numeric-devon",
   "metadata": {},
   "source": [
    "Any function you write with TensorFlow will contain a mixture of native TF operations and Python logic, such as if-then clauses, loops, break, return, continue, and more. While TensorFlow operations are easily captured by a tf.Graph, Python-specific logic needs to undergo an extra step in order to become part of the graph. tf.function uses a library called AutoGraph (tf.autograph) to convert Python code into graph-generating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equal-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "  if tf.greater(x, 0):\n",
    "    return x\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "respiratory-pacific",
   "metadata": {},
   "source": [
    "Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to see the exact results. These are not easy to read, so no need to look too carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "altered-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (retval_, do_return)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal retval_, do_return\n",
      "            (retval_, do_return) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('retval_', 'do_return'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph-generating output of AutoGraph.\n",
    "print(tf.autograph.to_code(simple_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "romantic-river",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_34\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_33\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_34\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_1\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_2\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_3\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_4\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    arg_attr {\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_33\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    arg_attr {\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 561\n",
      "  min_consumer: 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph itself.\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wired-richardson",
   "metadata": {},
   "source": [
    "Most of the time, tf.function will work without special considerations. However, there are some caveats, and the tf.function guide can help here, as well as the complete AutoGraph reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-mountain",
   "metadata": {},
   "source": [
    "### ii. Polymorphism: one Function, many graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "contemporary-namibia",
   "metadata": {},
   "source": [
    "A tf.Graph is specialized to a specific type of inputs (for example, tensors with a specific dtype or objects with the same id()).\n",
    "\n",
    "Each time you invoke a Function with new dtypes and shapes in its arguments, Function creates a new tf.Graph for the new arguments. The dtypes and shapes of a tf.Graph's inputs are known as an input signature or just a signature.\n",
    "\n",
    "The Function stores the tf.Graph corresponding to that signature in a ConcreteFunction. A ConcreteFunction is a wrapper around a tf.Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "  return tf.maximum(0., x)\n",
    "\n",
    "# `my_relu` creates new graphs as it sees more signatures.\n",
    "print(my_relu(tf.constant(5.5)))\n",
    "print(my_relu([1, -1]))\n",
    "print(my_relu(tf.constant([3., -3.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# If the Function has already been called with that signature, Function does not create a new tf.Graph.\n",
    "\n",
    "# These two calls do *not* create new graphs.\n",
    "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
    "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "standard-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "# Because it's backed by multiple graphs, we can say a Function is polymorphic. \n",
    "# That enables it to support more input types than a single tf.Graph could represent, \n",
    "# as well as to optimize each tf.Graph for better performance.\n",
    "\n",
    "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
    "# The `ConcreteFunction` also knows the return type and shape!\n",
    "print(my_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-shakespeare",
   "metadata": {},
   "source": [
    "## 3. Using tf.function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "educational-supervisor",
   "metadata": {},
   "source": [
    "So far, you've seen how you can convert a Python function into a graph simply by using tf.function as a decorator or wrapper. But in practice, getting tf.function to work correctly can be tricky! In the following sections, you'll learn how you can make your code work as expected with tf.function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-pendant",
   "metadata": {},
   "source": [
    "### i. Graph execution vs. eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complimentary-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in a Function can be executed both eagerly and as a graph. \n",
    "# By default, Function executes its code as a graph:\n",
    "\n",
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "leading-european",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 8 0 8 2], shape=(5,), dtype=int32)\n",
      "tf.Tensor([4 4 6 9 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alternate-identifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "concrete-vitamin",
   "metadata": {},
   "source": [
    "To verify that your Function's graph is doing the same computation as its equivalent Python function, we can make it execute eagerly with tf.config.run_functions_eagerly(True). This is a switch that turns off Function's ability to create and run graphs, instead executing the code normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "union-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "criminal-scoop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spanish-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to set it back when you are done.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "major-reach",
   "metadata": {},
   "source": [
    "However, Function can behave differently under graph and eager execution. The Python print function is one example of how these two modes differ. Let's see what happens when we insert a print statement to our function and call it repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brown-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  print(\"Calculating MSE!\")\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "whole-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "# Observe what is printed:\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "damaged-pottery",
   "metadata": {},
   "source": [
    "Is the output surprising? get_MSE only printed once even though it was called three times.\n",
    "\n",
    "To explain, the print statement is executed when Function runs the original code in order to create the graph in a process known as \"tracing\". Tracing captures the TensorFlow operations into a graph, and print is not captured in the graph. That graph is then executed for all three calls without ever running the Python code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "returning-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a sanity check, let's turn off graph execution to compare:\n",
    "\n",
    "# Now, globally set everything to run eagerly to force eager execution.\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "computational-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n",
      "Calculating MSE!\n",
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "# Observe what is printed below.\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "concerned-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "capital-madonna",
   "metadata": {},
   "source": [
    "print is a Python side effect, and there are other differences that you should be aware of when converting a function into a Function.\n",
    "\n",
    "Note: If you would like to print values in both eager and graph execution, use tf.print instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-dispatch",
   "metadata": {},
   "source": [
    "### ii. tf.function best practices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dangerous-civilian",
   "metadata": {},
   "source": [
    "t may take some time to get used to the behavior of Function. To get started quickly, first-time users should play around with decorating toy functions with @tf.function to get experience with going from eager to graph execution.\n",
    "\n",
    "Designing for tf.function may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:\n",
    "\n",
    "Toggle between eager and graph execution early and often with tf.config.run_functions_eagerly to pinpoint if/ when the two modes diverge.\n",
    "Create tf.Variables outside the Python function and modify them on the inside. The same goes for objects that use tf.Variable, like keras.layers, keras.Models and tf.optimizers.\n",
    "Avoid writing functions that depend on outer Python variables, excluding tf.Variables and Keras objects.\n",
    "Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but be careful!\n",
    "Include as much computation as possible under a tf.function to maximize the performance gain. For example, decorate a whole training step or the entire training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-stockholm",
   "metadata": {},
   "source": [
    "## 4. Seeing the speed-up"
   ]
  },
  {
   "cell_type": "raw",
   "id": "frequent-manhattan",
   "metadata": {},
   "source": [
    "tf.function usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "played-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "constitutional-michigan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 1.7657930999998825\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "organized-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution: 0.338703699999769\n"
     ]
    }
   ],
   "source": [
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "three-attachment",
   "metadata": {},
   "source": [
    "tf.function is commonly used to speed up training loops, as you can see here with Keras.\n",
    "\n",
    "Note: You can also try tf.function(jit_compile=True) for a more significant performance boost, especially if your code is heavy on TF control flow and uses many small tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-platinum",
   "metadata": {},
   "source": [
    "### i. Performance and trade-offs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "terminal-coral",
   "metadata": {},
   "source": [
    "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. This investment is usually quickly paid back with with the performance boost of subsequent executions, but it's important to be aware that the first few steps of any large model training can be slower due to tracing.\n",
    "\n",
    "No matter how large your model, you want to avoid tracing frequently. The tf.function guide discusses how to set input specifications and use tensor arguments to avoid retracing. If you find you are getting unusually poor performance, it's a good idea to check if you are retracing accidentally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-penny",
   "metadata": {},
   "source": [
    "## 5. When is a Function tracing?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "strong-breakfast",
   "metadata": {},
   "source": [
    "To figure out when your Function is tracing, add a print statement to its code. As a rule of thumb, Function will execute the print statement every time it traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accurate-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "  print(\"Tracing!\") # An eager-only side effect.\n",
    "  return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time.\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "# The second time through, you won't see the side effect.\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quality-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter.\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ordered-chassis",
   "metadata": {},
   "source": [
    "Here, you see extra tracing because new Python arguments always trigger the creation of a new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-mountain",
   "metadata": {},
   "source": [
    "# reference\n",
    "\n",
    "### https://tensorflow.google.cn/guide/intro_to_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-insurance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
