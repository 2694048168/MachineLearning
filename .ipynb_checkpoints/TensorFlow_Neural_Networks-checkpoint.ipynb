{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "### Deep Learning\n",
    "### Neural Networks\n",
    "### 环境搭建详细教程\n",
    "- Windows 10\n",
    "- Ubuntu 18.04/16.04/20.04\n",
    "- TensorFlow\n",
    "- PyTorch\n",
    "- CUDA cuDNN\n",
    "- Jupyter Lab & Jupyter Notebook\n",
    "- PyCharm\n",
    "\n",
    "[环境搭建详细教程——GitHub-Blog](https://2694048168.github.io/)\n",
    "\n",
    "[环境搭建详细教程——Gitee-Blog](http://weili_yzzcq.gitee.io/)\n",
    "\n",
    "[环境搭建详细教程——CSDN-Blog](https://blog.csdn.net/weixin_46782218)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, w = 0, error = 5565.107834483211\n",
      "Running\n",
      "After 1000 iterations b = 0.08893651993741346, w = 1.4777440851894448, error = 112.61481011613473\n"
     ]
    }
   ],
   "source": [
    "# 线性回归\n",
    "# make decisions: discrete 离散值     continuous 连续值\n",
    "# continuous prediction：input data（x）；prediction（f，参数 θ theta）；real data，ground-truth（y）\n",
    "# linear equation 线性方程组 y = w * x + b + epsilon\n",
    "# with noise  epsilon 噪声 高斯分布\n",
    "# find the W and b\n",
    "# loss = (WX + b - Y)**2\n",
    "# miniize loss \n",
    "# gradient descent GD 梯度下降 一维和二维可视化\n",
    "# loss surface\n",
    "# linear regression\n",
    "# logistic regression\n",
    "# classification\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 生成 csv 文件里面的数据\n",
    "# data = []\n",
    "# for i in range(100):\n",
    "# \tx = np.random.uniform(3., 12.)\n",
    "# \t# mean=0, std=0.1\n",
    "# \teps = np.random.normal(0., 0.1)\n",
    "# \ty = 1.477 * x + 0.089 + eps\n",
    "# \tdata.append([x, y])\n",
    "# data = np.array(data)\n",
    "# print(data.shape, data)\n",
    "\n",
    "# cpmputer loss\n",
    "# Y = W*X +b\n",
    "def computer_error_for_line_given_points(b, w, points):\n",
    "    total_error = 0\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # computer mean-squared-error\n",
    "        total_error += ((w * x + b) - y) ** 2\n",
    "        # total_error += (y - (w * x + b)) ** 2\n",
    "    # average loss for each point\n",
    "    return total_error / float(len(points))\n",
    "\n",
    "# computer Gradient and update\n",
    "def step_gradient(b_current, w_current, points, learning_rate):\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # grad_b = 2(wx + b - y)\n",
    "        b_gradient += (2/N) * ((w_current * x + b_current) - y)\n",
    "        # grad_w = 2(wx + b - y) * x\n",
    "        w_gradient += (2/N) * x * ((w_current * x + b_current) - y)\n",
    "    # update the grad_w, and the grad_b\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_w = w_current - (learning_rate * w_gradient)\n",
    "    return [new_b, new_w]\n",
    "\n",
    "# set w = w_new and loop\n",
    "def gradient_descent_runner(points, starting_b, starting_w, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    # update for several times\n",
    "    for i in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), learning_rate)\n",
    "    return [b, w]\n",
    "\n",
    "\n",
    "# running the linear regression model\n",
    "# loading the data for numpy from the data.cvs file\n",
    "# the data shape is 100 * 2 (row * column)\n",
    "points = np.genfromtxt(\"./datasets/data.csv\", delimiter=\",\")\n",
    "# init the Hyperparameter\n",
    "learning_rate = 0.0001\n",
    "initial_b = 0\n",
    "initial_w = 0\n",
    "num_iterations = 1000\n",
    "# show the initial Hyperparameter for linear regression model and the error\n",
    "print(\"Starting gradient descent at b = {0}, w = {1}, error = {2}\"\n",
    "      .format(initial_b, initial_w, computer_error_for_line_given_points(initial_b, initial_w, points)))\n",
    "\n",
    "print(\"Running\")\n",
    "# iterations = 1000,computer the Hyperparameter for linear regression model\n",
    "[b, w] = gradient_descent_runner(points, initial_b, initial_w, learning_rate, num_iterations)\n",
    "\n",
    "# and show the Hyperparameter for linear regression model and the error\n",
    "print(\"After {0} iterations b = {1}, w = {2}, error = {3}\"\n",
    "      .format(num_iterations, b, w, computer_error_for_line_given_points(b, w, points)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n",
      "第 0 次 epoch，第 100 step，该次训练 loss = 1.6492801904678345\n",
      "第 0 次 epoch，第 200 step，该次训练 loss = 0.9574925899505615\n",
      "第 0 次 epoch，第 300 step，该次训练 loss = 0.7756418585777283\n",
      "第 1 次 epoch，第 100 step，该次训练 loss = 0.677655816078186\n",
      "第 1 次 epoch，第 200 step，该次训练 loss = 0.7041688561439514\n",
      "第 1 次 epoch，第 300 step，该次训练 loss = 0.5958806872367859\n",
      "第 2 次 epoch，第 100 step，该次训练 loss = 0.5593937039375305\n",
      "第 2 次 epoch，第 200 step，该次训练 loss = 0.6061217188835144\n",
      "第 2 次 epoch，第 300 step，该次训练 loss = 0.5171711444854736\n",
      "第 3 次 epoch，第 100 step，该次训练 loss = 0.500190794467926\n",
      "第 3 次 epoch，第 200 step，该次训练 loss = 0.5500799417495728\n",
      "第 3 次 epoch，第 300 step，该次训练 loss = 0.4704623818397522\n",
      "第 4 次 epoch，第 100 step，该次训练 loss = 0.4624771773815155\n",
      "第 4 次 epoch，第 200 step，该次训练 loss = 0.5116350054740906\n",
      "第 4 次 epoch，第 300 step，该次训练 loss = 0.43804916739463806\n",
      "第 5 次 epoch，第 100 step，该次训练 loss = 0.4350418448448181\n",
      "第 5 次 epoch，第 200 step，该次训练 loss = 0.48301219940185547\n",
      "第 5 次 epoch，第 300 step，该次训练 loss = 0.41369202733039856\n",
      "第 6 次 epoch，第 100 step，该次训练 loss = 0.41353902220726013\n",
      "第 6 次 epoch，第 200 step，该次训练 loss = 0.46057674288749695\n",
      "第 6 次 epoch，第 300 step，该次训练 loss = 0.39432698488235474\n",
      "第 7 次 epoch，第 100 step，该次训练 loss = 0.39585599303245544\n",
      "第 7 次 epoch，第 200 step，该次训练 loss = 0.442291796207428\n",
      "第 7 次 epoch，第 300 step，该次训练 loss = 0.3781718909740448\n",
      "第 8 次 epoch，第 100 step，该次训练 loss = 0.3807425796985626\n",
      "第 8 次 epoch，第 200 step，该次训练 loss = 0.42688846588134766\n",
      "第 8 次 epoch，第 300 step，该次训练 loss = 0.36439192295074463\n",
      "第 9 次 epoch，第 100 step，该次训练 loss = 0.367557168006897\n",
      "第 9 次 epoch，第 200 step，该次训练 loss = 0.4134664833545685\n",
      "第 9 次 epoch，第 300 step，该次训练 loss = 0.35241368412971497\n",
      "第 10 次 epoch，第 100 step，该次训练 loss = 0.3557971119880676\n",
      "第 10 次 epoch，第 200 step，该次训练 loss = 0.40170928835868835\n",
      "第 10 次 epoch，第 300 step，该次训练 loss = 0.3418275713920593\n",
      "第 11 次 epoch，第 100 step，该次训练 loss = 0.34523069858551025\n",
      "第 11 次 epoch，第 200 step，该次训练 loss = 0.39130812883377075\n",
      "第 11 次 epoch，第 300 step，该次训练 loss = 0.33241990208625793\n",
      "第 12 次 epoch，第 100 step，该次训练 loss = 0.33555713295936584\n",
      "第 12 次 epoch，第 200 step，该次训练 loss = 0.3819326162338257\n",
      "第 12 次 epoch，第 300 step，该次训练 loss = 0.3239107131958008\n",
      "第 13 次 epoch，第 100 step，该次训练 loss = 0.3267011344432831\n",
      "第 13 次 epoch，第 200 step，该次训练 loss = 0.37346935272216797\n",
      "第 13 次 epoch，第 300 step，该次训练 loss = 0.3161661624908447\n",
      "第 14 次 epoch，第 100 step，该次训练 loss = 0.31853535771369934\n",
      "第 14 次 epoch，第 200 step，该次训练 loss = 0.3657045364379883\n",
      "第 14 次 epoch，第 300 step，该次训练 loss = 0.309009313583374\n",
      "第 15 次 epoch，第 100 step，该次训练 loss = 0.31101059913635254\n",
      "第 15 次 epoch，第 200 step，该次训练 loss = 0.3585987091064453\n",
      "第 15 次 epoch，第 300 step，该次训练 loss = 0.30239829421043396\n",
      "第 16 次 epoch，第 100 step，该次训练 loss = 0.3040561378002167\n",
      "第 16 次 epoch，第 200 step，该次训练 loss = 0.35202449560165405\n",
      "第 16 次 epoch，第 300 step，该次训练 loss = 0.2962380647659302\n",
      "第 17 次 epoch，第 100 step，该次训练 loss = 0.2976039946079254\n",
      "第 17 次 epoch，第 200 step，该次训练 loss = 0.34592434763908386\n",
      "第 17 次 epoch，第 300 step，该次训练 loss = 0.29047834873199463\n",
      "第 18 次 epoch，第 100 step，该次训练 loss = 0.2915274500846863\n",
      "第 18 次 epoch，第 200 step，该次训练 loss = 0.3402198851108551\n",
      "第 18 次 epoch，第 300 step，该次训练 loss = 0.2851108908653259\n",
      "第 19 次 epoch，第 100 step，该次训练 loss = 0.28578639030456543\n",
      "第 19 次 epoch，第 200 step，该次训练 loss = 0.3348488509654999\n",
      "第 19 次 epoch，第 300 step，该次训练 loss = 0.28010454773902893\n",
      "第 20 次 epoch，第 100 step，该次训练 loss = 0.2803708016872406\n",
      "第 20 次 epoch，第 200 step，该次训练 loss = 0.3297297954559326\n",
      "第 20 次 epoch，第 300 step，该次训练 loss = 0.2754082977771759\n",
      "第 21 次 epoch，第 100 step，该次训练 loss = 0.2752252519130707\n",
      "第 21 次 epoch，第 200 step，该次训练 loss = 0.3248599171638489\n",
      "第 21 次 epoch，第 300 step，该次训练 loss = 0.27102020382881165\n",
      "第 22 次 epoch，第 100 step，该次训练 loss = 0.27042156457901\n",
      "第 22 次 epoch，第 200 step，该次训练 loss = 0.32023605704307556\n",
      "第 22 次 epoch，第 300 step，该次训练 loss = 0.2669133245944977\n",
      "第 23 次 epoch，第 100 step，该次训练 loss = 0.2658783793449402\n"
     ]
    }
   ],
   "source": [
    "# Image Classification\n",
    "# hand-written digits recognition\n",
    "# MNIST: 7,000 images per category = 70,000\n",
    "# train / test splitting = 60k / 10k\n",
    "# [28, 28, 1] = [rows,columns, gray_value]\n",
    "# 28 * 28 = 784 转换为一维数组\n",
    "# input and output\n",
    "# coding the features for data: one-hot\n",
    "# regression VS classification\n",
    "# y = w * x + b\n",
    "# y 属于空间 R^d\n",
    "# out = X @ W + b\n",
    "# out:[0.1, 0.8, 0.02,.0.08] = 1 概率，最大值概率称之为置信度\n",
    "# pred = argmax(out)\n",
    "\n",
    "# out = X @ W + b\n",
    "# X = [b, 784]\n",
    "# W = [784, 10]\n",
    "# b = [10]\n",
    "\n",
    "# it is linear !\n",
    "# out = X @ W + b\n",
    "# 变成 non-linear !\n",
    "# out = f(X @ W + b)\n",
    "# 引入非线性因子，这个 f 函数称之为激活函数，\n",
    "# f = ReLu function and sigmoid function\n",
    "# out = relu(X @ W + b)\n",
    "\n",
    "# it is simple\n",
    "# out = relu(X @ W + b)\n",
    "# 添加隐藏层 hide layer\n",
    "# h1 = relu(X @ W1 + b1)\n",
    "# h2 = relu(X @ W2 + b2)\n",
    "# out = relu(X @ W3 + b3)\n",
    "\n",
    "# particularly\n",
    "# 每一层都是类似降维的过程，直到从 [1, 784] ---- [1, 10]\n",
    "# X = [v1, v2, ... , v784]\n",
    "# h1 = relu(X @ W1 + b1)\n",
    "#    W1: [784, 512]\n",
    "#    b1: [1, 512]\n",
    "# h2 = relu(X @ W2 + b2)\n",
    "#    W2: [512, 256]\n",
    "#    b2: [1, 256]\n",
    "# out = relu(X @ W3 + b3)\n",
    "#    W2: [256, 10]\n",
    "#    b2: [1, 10]\n",
    "\n",
    "# loss\n",
    "# out:[1, 10]\n",
    "# Y/label: 0-9 （one-hot）\n",
    "# euclidean distance 计算欧式距离 使得 out 接近 label   MSE\n",
    "# loss = (Y - out) **2\n",
    "\n",
    "# in a nutshell\n",
    "# out = relu{relu{relu[X @ W1 + b1] @ W2 + b2 } @ W3 + b3}\n",
    "# pred = argmax(out)\n",
    "# loss = MSE(out, label)\n",
    "# minimize loss\n",
    "# [w1_new, b2_new, w2_new, b2_new, w3_new, b3_new]\n",
    "\n",
    "# Deep Learning\n",
    "# classification precedure\n",
    "# step1 compute [h1, h2, out]\n",
    "# step2 compute loss\n",
    "# step3 compute gradient and update [w1_new, b2_new, w2_new, b2_new, w3_new, b3_new]\n",
    "# step4 loop\n",
    "# need TensorFlow\n",
    "\n",
    "# 以下两条语句，使得 TensorFlow 少打印出一些无关紧要的信息\n",
    "# import  os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "# step 0 loading data X and Y\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data() \n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "print(x.shape, y.shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# batch 概念\n",
    "train_dataset = train_dataset.batch(200)\n",
    "    \n",
    "# step 0 model NN\n",
    "model = tf.keras.Sequential([layers.Dense(512, activation=\"relu\"),\n",
    "                          layers.Dense(256, activation=\"relu\"),\n",
    "                          layers.Dense(10)])\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# 对整个训练集 训练 30 次，即就是 epoch = 30 \n",
    "# 将训练集数据划分为每次读取 200 ，即就是 batch = 200\n",
    "# 那么 step = train_data / batch = 60k / 200 = 300\n",
    "# 每训练 100 个样本数据，就查看一次训练情况 loss\n",
    "# 实际显示的 loss 情况次数 = epoch * (step / 100) = 30 * (300/100) = 90\n",
    "\n",
    "# step4 loop\n",
    "# 对一个数据集 dataset 训练一次称之为 epoch\n",
    "def train_epoch(epoch):\n",
    "    # 对一个 batch 训练一次称之为 step\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # [b， 28， 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # step 1 compute output\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = model(x)\n",
    "            # step2 compute loss\n",
    "            loss = tf.reduce_sum(tf.square(out - y)) / x.shape[0]\n",
    "            \n",
    "        # step 3 optimize and update w1, w2, w3, b1, b2, b3\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # w_new = w - lr * grad\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables)) \n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            # print(epoch, step, 'loss:', loss.numpy())\n",
    "            print(\"第 {0} 次 epoch，第 {1} step，该次训练 loss = {2}\".format(epoch, step+100, loss.numpy()))\n",
    "\n",
    "# 对整个数据集训练多次 30 次\n",
    "for epoch in range(30):\n",
    "    train_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 数据类型\n",
    "# data container: list, np.array, tf.Tensor\n",
    "# what is Tensor\n",
    "# - scalar 标量 1.1\n",
    "# - vector 向量 [1.1], [1.1, 2.2]\n",
    "# - matrix 矩阵 [[1.1, 2.2], [3.3, 4.4], [5.5, 6.6]]\n",
    "# - tensor rank > 2 矩阵的秩\n",
    "# TF is a computing lib\n",
    "# - int, float, double, bool, string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# create the int, float, double, bool, string\n",
    "tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(1.2, dtype=tf.int32)\n",
    "# TypeError: Cannot convert 1.2 to EagerTensor of dtype int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant([True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Property 常见属性\n",
    "with tf.device(\"cpu\"):\n",
    "    const_cpu = tf.constant([1])\n",
    "\n",
    "with tf.device(\"gpu\"):\n",
    "    const_gpu = tf.range(4)\n",
    "    \n",
    "# device 属性，查看 Tensor 在哪一个设备上 CPU or GPU\n",
    "const_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_gpu.device\n",
    "# 因为本地没有安装 GPU 加速驱动 CUDA 和 cuDNN\n",
    "# 无法提供 GPU 加速环境，故此工作环境依旧还在 CPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相互转换 \n",
    "# const_cpu_to_gpu = const_cpu.gpu()\n",
    "# const_cpu_to_gpu.device\n",
    "\n",
    "const_gpu_to_cpu = tf.identity(const_gpu)\n",
    "const_gpu_to_cpu.device\n",
    "\n",
    "# tensor 的计算必须在同一设备进行，全部都是 CPU 或者全部都是 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 属性，将 Tensor 转换为 numpy\n",
    "# numpy 是在 CPU 上的\n",
    "const_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 Tensor 的 shape 维度\n",
    "# ndim 属性，返回 Tensor 的维度信息\n",
    "# rank 方法，返回 Tensor 的维度信息\n",
    "const_cpu.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.rank(const_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.rank(tf.ones([3, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断是否 Tensor\n",
    "tf.is_tensor(const_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为 Tensor\n",
    "const = np.arange(5)\n",
    "const_tensor = tf.convert_to_tensor(const)\n",
    "const_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dtype\n",
    "# 数值类型之间的转换\n",
    "const_cpu.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(const_tensor, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(const_tensor, dtype=tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(const_tensor, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int <==> bool\n",
    "bool_num = tf.constant([0, 1])\n",
    "bool_num_bool = tf.cast(bool_num, dtype=tf.bool)\n",
    "bool_num_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(bool_num_bool, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable\n",
    "# 一般是需要优化的变量参数\n",
    "a = tf.range(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.trainable\n",
    "# 需要梯度信息，可以自动求导\n",
    "# 神经网络的参数需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.is_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Tensor\n",
    "# from numpy, list\n",
    "# zeros, ones\n",
    "# fill\n",
    "# random\n",
    "# constant\n",
    "# Applicatin\n",
    "\n",
    "# meta-learning\n",
    "\n",
    "# Tensor 索引和切片\n",
    "# selecetive indexing\n",
    "# tf.gather() , tf.gather_nd(), tf.boolean_mask()\n",
    "\n",
    "# 维度变换\n",
    "# shape, ndim\n",
    "# reshape\n",
    "# expand_dims, squeeze\n",
    "# transpose\n",
    "# broadcast_to\n",
    "\n",
    "# 数学计算\n",
    "# +, -, *, /, **, pow, square, sqrt, //, %, exp, log, @, matmul\n",
    "# element_wise, matrix_wise, dim_wise, \n",
    "# 元素级计算，矩阵级计算，维度级计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  os\n",
    "# 复制 0， 1， 2，打印 c++ 一些信息\n",
    "# 0 打印全部信息\n",
    "# 2 只打印 error 信息\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "# loading the dataset MNIST\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "\n",
    "# set the iteration\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播 forward\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# loading data\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "\n",
    "# convert to Tensor\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "# show the info\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the dataset and split the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print(\"batch\", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 权值\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "# tf.Variable 才会自动记录梯度信息，tf.Tensor 不会记录梯度信息，故此值为 None，类型为 NoneType\n",
    "# 需要给一个好点的初始值，否则容易 loss 爆炸，出现 nan(not a number) 情况,stddev=0.1 方差给小一点\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 学习率 ，步长 10^-3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 对数据集迭代 10 次\n",
    "for epoch in range(10):\n",
    "    # 对数据集一次循环\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x [128, 28, 28]\n",
    "        # y [128]\n",
    "        # 进行维度转换 [128, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])   \n",
    "    \n",
    "        # 自动求导过程,梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            # x [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            # 添加非线性，relu 激活函数\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 +b3\n",
    "        \n",
    "            # compute loss\n",
    "            # out [b, 10]\n",
    "            # y [b] => [b, 10]\n",
    "            y_one_hot = tf.one_hot(y, depth=10)\n",
    "        \n",
    "            # MSE = mean((y - out)**2)\n",
    "            loss = tf.square(y_one_hot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "    \n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # 原地更新，否则就返回 tf.Tensor 类型了，无法进行下一个梯度更新\n",
    "        # w1 = w1 - learning_rate * grads[0]\n",
    "        w1.assign_sub(learning_rate * grads[0])\n",
    "        b1.assign_sub(learning_rate * grads[1])\n",
    "        w2.assign_sub(learning_rate * grads[2])\n",
    "        b2.assign_sub(learning_rate * grads[3])\n",
    "        w3.assign_sub(learning_rate * grads[4])\n",
    "        b3.assign_sub(learning_rate * grads[5])\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, \"loss\", float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 张量的合并和分割\n",
    "# tf.concat 合并\n",
    "# tf.split  分割\n",
    "# tf.stack 合并\n",
    "# tf.unstack 分割\n",
    "\n",
    "# 数据统计\n",
    "# tf.norm 范数概念\n",
    "# tf.reduce_min/max/mean\n",
    "# tf.argmax/argminx\n",
    "# tf.equal\n",
    "# tf.unique\n",
    "\n",
    "# 张量排序 Tensor 排序\n",
    "# tf.sort、tf.argsort\n",
    "# top_k\n",
    "# top_k compute of accuracy\n",
    "\n",
    "# 填充与复制\n",
    "# pad\n",
    "# tile\n",
    "# broadcast_to\n",
    "\n",
    "# 张量限幅\n",
    "# clip_by_value\n",
    "# relu\n",
    "# clip_by_norm\n",
    "# gradient clipping\n",
    "\n",
    "# 高阶操作\n",
    "# where\n",
    "# scatter_nd\n",
    "# meshgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集加载\n",
    "# keras.datasets\n",
    "# tf.data.Dataset.from_tensor_sclices : shuffle, map, batch, repeat\n",
    "# input pipeline\n",
    "# such as : boston housing, mnist/fashion mnist, cifar10/100, imdb\n",
    "\n",
    "# 前向传播 forward\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "# loading data\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# convert to Tensor\n",
    "# x : [0-255] -> [0-1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "# show the info\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "# set the dataset and split the batch\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)\n",
    "\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print(\"batch\", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 权值\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "# tf.Variable 才会自动记录梯度信息，tf.Tensor 不会记录梯度信息，故此值为 None，类型为 NoneType\n",
    "# 需要给一个好点的初始值，否则容易 loss 爆炸，出现 nan(not a number) 情况,stddev=0.1 方差给小一点\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 学习率 ，步长 10^-3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 对数据集迭代 100 次\n",
    "# for epoch in range(10): # test acc = 0.5566\n",
    "for epoch in range(100): # test acc = 0.8531\n",
    "    # 对数据集一次循环\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x [128, 28, 28]\n",
    "        # y [128]\n",
    "        # 进行维度转换 [128, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])   \n",
    "    \n",
    "        # 自动求导过程,梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            # x [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            # 添加非线性，relu 激活函数\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 +b3\n",
    "        \n",
    "            # compute loss\n",
    "            # out [b, 10]\n",
    "            # y [b] => [b, 10]\n",
    "            y_one_hot = tf.one_hot(y, depth=10)\n",
    "        \n",
    "            # MSE = mean((y - out)**2)\n",
    "            loss = tf.square(y_one_hot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "    \n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # 原地更新，否则就返回 tf.Tensor 类型了，无法进行下一个梯度更新\n",
    "        # w1 = w1 - learning_rate * grads[0]\n",
    "        w1.assign_sub(learning_rate * grads[0])\n",
    "        b1.assign_sub(learning_rate * grads[1])\n",
    "        w2.assign_sub(learning_rate * grads[2])\n",
    "        b2.assign_sub(learning_rate * grads[3])\n",
    "        w3.assign_sub(learning_rate * grads[4])\n",
    "        b3.assign_sub(learning_rate * grads[5])\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, \"loss\", float(loss))\n",
    "    \n",
    "    # test/evluation\n",
    "    total_correct, total_num = 0, 0\n",
    "    for step, (x, y) in enumerate(test_db):\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        \n",
    "        h1 = tf.nn.relu(x@w1 + b1)\n",
    "        h2 = tf.nn.relu(h1@w2 + b2)        \n",
    "        out = h2@w3 + b3\n",
    "        \n",
    "        prob = tf.nn.softmax(out, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        \n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "        \n",
    "    acc = total_correct / total_num\n",
    "    print(\"test acc : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全连接层\n",
    "# matmul\n",
    "# neural network\n",
    "# deep learning\n",
    "# multi-layer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "x = tf.random.normal([2, 3])\n",
    "\n",
    "model = keras.Sequential([\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(2)]) # 没有加 relu 非线性的这一层，称之为 logits\n",
    "\n",
    "model.build(input_shape=[None, 3])\n",
    "model.summary()\n",
    "\n",
    "for p in model.trainable_variables:\n",
    "    print(p.name, p.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出方式\n",
    "# such as : R 整个实数集，[0-1]输出概率值，[0-1]&所有概率和为1，[-1-1]范围\n",
    "# tf.sigmoid => [0-1] => sigmoid 激活函数以及压缩\n",
    "# tf.nn.softmax => [0-1]&所有概率之和为 1 => softmax 函数\n",
    "# tf.tanh => [-1 -1] => 通过 sigmoid 函数扩大到 [0-2],然后平移到 [-1 -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "# MSE\n",
    "# Cross Entropy Loss 熵 交叉熵 散度\n",
    "# Hinge Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度下降\n",
    "# gradient descent\n",
    "# auto gradient\n",
    "# with tf.GradientTape() as tape:\n",
    "# 二阶求导  2nd-order\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "# 二阶求导\n",
    "with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2:\n",
    "        y = x * w + b\n",
    "    dy_dw, dy_db = tape2.gradient(y, [w, b])\n",
    "d2y_dw2 = tape1.gradient(dy_dw, w)\n",
    "\n",
    "print(dy_dw)\n",
    "print(dy_db)\n",
    "print(d2y_dw2)\n",
    "\n",
    "assert dy_dw.numpy() == 3.0\n",
    "assert d2y_dw2 is None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions 激活函数\n",
    "# 激活函数及其梯度\n",
    "# 温水煮青蛙\n",
    "# sigmoid logistic\n",
    "\n",
    "# loss及其梯度\n",
    "# softmax\n",
    "\n",
    "# 单输出感知器模型及其梯度\n",
    "# Single-output Perceptron\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.normal([1, 3])\n",
    "w = tf.ones([3, 1])\n",
    "b = tf.ones([1])\n",
    "y = tf.constant([1])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    logits = tf.sigmoid(x@w +b)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(y, logits))\n",
    "    \n",
    "grads = tape.gradient(loss, [w, b])\n",
    "print(grads[0])\n",
    "print(grads[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多输出感知器模型及其梯度\n",
    "# Multi-output Perceptron\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.normal([2, 4])\n",
    "w = tf.random.normal([4, 3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2, 0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    prob = tf.nn.softmax(x@w + b, axis=1)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(tf.one_hot(y, depth=3), prob))\n",
    "    \n",
    "grads = tape.gradient(loss, [w, b])\n",
    "print(grads[0])\n",
    "print(grads[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 链式法则\n",
    "# chain rule\n",
    "# 神经网络层 权值不断更新\n",
    "\n",
    "# 多层感知器 \n",
    "# Multi-Layer Perceptron\n",
    "# 反向传播算法\n",
    "\n",
    "# Himmelblau 函数优化\n",
    "# f(x, y) = (x**2 + y - 11)**2 + (x + y**2 -7)**2\n",
    "# Himmelblau function 常用于测试算法模型\n",
    "# Himmelblau 方程，是科学家们研究出来专门用于检测一个优化器效果的方程\n",
    "# 四个点（最小值）精确解\n",
    "# f(3.0, 2.0) = 0.0; f(-2.805118, 3.131312) = 0.0; f(-3.779310, -3.283186) = 0.0; f(3.584428, -1.848126) = 0.0; \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# This is important for 3d plotting \n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "def himmelblau(x):\n",
    "    return (x[0] **2 + x[1] - 11) **2 + (x[0] + x[1] **2 - 7) **2\n",
    "\n",
    "x = np.arange(-6, 6, 0.1)\n",
    "y = np.arange(-6, 6, 0.1)\n",
    "print(\"x, y range: \", x.shape, y.shape)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "print(\"X, Y maps: \", X.shape, Y.shape)\n",
    "Z = himmelblau([X, Y])\n",
    "\n",
    "# 可视化 himmelblau 函数\n",
    "fig = plt.figure(\"himmelblau\")\n",
    "# ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, Z)\n",
    "ax.view_init(60, -30)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# gradient descent\n",
    "# 初始点位置\n",
    "# x = tf.constant([-4., 0.])\n",
    "x = tf.constant([4., 0.])\n",
    "\n",
    "for step in range(200):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([x])\n",
    "        y = himmelblau(x)\n",
    "        \n",
    "    grads = tape.gradient(y, [x])[0]\n",
    "    x -= 0.01 * grads\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(\"step {}: x = {}, f(x) = {}\".format(step, x.numpy(), y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "# data processing 数据预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "    \n",
    "# loading dataset\n",
    "(x, y), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# 数据预处理 映射函数即可\n",
    "db_train = db_train.map(preprocess)\n",
    "# shuffle and batch 操作\n",
    "batch_size = 128\n",
    "db_train = db_train.shuffle(10000).batch(batch_size)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "# 数据预处理 映射函数即可\n",
    "db_test = db_test.map(preprocess)\n",
    "# shuffle and batch 操作\n",
    "db_test = db_test.shuffle(10000).batch(batch_size)\n",
    "\n",
    "# sample 操作\n",
    "db_train_iter = iter(db_train)\n",
    "sample = next(db_train_iter)\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 神经网络层构建\n",
    "model = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "model.build(input_shape=[None, 28*28])\n",
    "model.summary()\n",
    "\n",
    "# 优化器 learning_rate\n",
    "# w = w - lrarning_rete * gradient\n",
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "\n",
    "def main():\n",
    "    # 对数据集循环训练多少次 epoch\n",
    "    for epoch in range(10):\n",
    "        # 对每个 batch 循环训练\n",
    "        for step, (x, y) in enumerate(db_train):\n",
    "            # 维度转换\n",
    "            # x: [b, 28, 28] => [b, 784]\n",
    "            # y: [b]\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # 跟踪梯度信息，自动求导\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 784] => [b, 10]\n",
    "                logits = model(x)\n",
    "                # compute loss\n",
    "                y_one_hot = tf.one_hot(y, depth=10)\n",
    "                # [b]\n",
    "                loss_mse = tf.reduce_mean(tf.losses.MSE(y_one_hot, logits))\n",
    "                loss_ce = tf.losses.categorical_crossentropy(y_one_hot, logits, from_logits=True)\n",
    "                loss_ce = tf.reduce_mean(loss_ce)\n",
    "            \n",
    "            # 获取梯度\n",
    "            grads = tape.gradient(loss_ce, model.trainable_variables)\n",
    "            # grads = tape.gradient(loss_mse, model.trainable_variables)\n",
    "            # 更新梯度\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "            # 每 100 次训练后查看 loss\n",
    "            if step % 100 == 0:\n",
    "                print(epoch, step, \" loss: \", float(loss_ce), float(loss_mse))\n",
    "        \n",
    "        # test\n",
    "        # 统计正确个数\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for x, y in db_test:\n",
    "            # 维度变换\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # [b, 10]\n",
    "            logits = model(x)\n",
    "            # 计算概率最大的位置索引\n",
    "            # logits => prob,  [b, 10]\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            # [b, 10] => [b] pred\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # 不需要 one_hot 编码\n",
    "            # correct : [b], True: equal; False: not equal\n",
    "            correct = tf.equal(pred, y)\n",
    "            # 将 bool 转换为 int （1或者0）\n",
    "            correct = tf.cast(correct, dtype=tf.int32)\n",
    "            # 计算正确个数\n",
    "            correct = tf.reduce_sum(correct)\n",
    "            \n",
    "            total_correct += int(correct)\n",
    "            total_num += x.shape[0]\n",
    "            \n",
    "        # compute the accurate\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, \"test acc : \", acc)\n",
    "            \n",
    "\n",
    "# if __name__ == \" __main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 可视化 Tensor 在数据流中 flow 过程\n",
    "# Visdom 可视化\n",
    "# 监控数据流 TensorBoard\n",
    "# tensorboard 会监听磁盘数据变换，使用 web UI 界面展示出来\n",
    "# 1、installation 2、curves 3、image visualization\n",
    "# principle：1、listen logdir 2、build summary instance 3、fed data into summary instance\n",
    "# steps：\n",
    "# step 1、run listener：cmd; cd logdir; tensorboard --logdir logs; web site:6006\n",
    "# step 2、buld summary: 代码中实现 \n",
    "# =================================================================\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# log_dir = \"logs\" + current_time\n",
    "# summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "# =================================================================\n",
    "# step 3、feed scalar: 代码中实现 \n",
    "# =================================================================\n",
    "# wtih summary_writer.as_default():\n",
    "#     tf.summary.scalar(\"loss\", float(loss), step=epoch)\n",
    "#     tf.summary.scalar(\"accuracy\", float(train_accuracy), step=epoch)\n",
    "# =================================================================\n",
    "# step 4、feed single image or multi-images: 代码中实现\n",
    "# \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io\n",
    "\n",
    "# data processing 数据预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "# plot figure to image PNG\n",
    "def plot_to_image(figure):\n",
    "    # convert the matplotlib plot specified by 'figure' to a PNG image and return it.\n",
    "    # the supplied figure is closed and inaccessible after the call.\n",
    "    \n",
    "    # save the plot to a PNG in memory\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # closing the figure prevents it from being dispalyed directly inside\n",
    "    # the notebook\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# fed multi-images\n",
    "def image_grid(images):\n",
    "    # return a 5X5 grid of the MNIST images as a matplotlib figure.\n",
    "    \n",
    "    # create a figure to contain the plot\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        # start next subplot\n",
    "        plt.subplot(5, 5, i + 1, title=\"name\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "    \n",
    "    return figure\n",
    "\n",
    "# batch\n",
    "batch_size = 128\n",
    "# loading dataset\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print(\"datasets: \", x.shape, y.shape, x.min, y.max)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# 数据预处理 映射函数即可  shuffle and batch 操作\n",
    "db = db.map(preprocess).shuffle(60000).batch(batch_size).repeat(10)\n",
    "\n",
    "# 构造 TensorFlow 需求的数据集\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "# 数据预处理 映射函数即可  shuffle and batch 操作\n",
    "ds_val = ds_val.map(preprocess).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# 神经网络层构建 5 layers\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "network.build(input_shape=[None, 28*28])\n",
    "network.summary()\n",
    "\n",
    "# 优化器 learning_rate\n",
    "# w = w - lrarning_rete * gradient\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "# TensorBoard 可视化操作步骤，监听磁盘路径\n",
    "# logs/ 文件夹 与该程序文件是同级\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/\" + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# get x from (x, y)\n",
    "sample_img = next(iter(db))[0]\n",
    "\n",
    "# get first image instance\n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "\n",
    "# TensorBoard 可视化操作步骤，写入数据 image\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample : \", sample_img, step=0)\n",
    "    \n",
    "\n",
    "# \n",
    "# 对每个 batch 循环训练\n",
    "for step, (x, y) in enumerate(db):\n",
    "    # 跟踪梯度信息，自动求导\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 维度转换\n",
    "        # x: [b, 28, 28] => [b, 784]\n",
    "        # y: [b]\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # compute loss\n",
    "        y_one_hot = tf.one_hot(y, depth=10)\n",
    "        # [b]\n",
    "        # loss_mse = tf.reduce_mean(tf.losses.MSE(y_one_hot, logits))\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_one_hot, out, from_logits=True))\n",
    "            \n",
    "    # 获取梯度\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    # grads = tape.gradient(loss_mse, network.trainable_variables)\n",
    "    # 更新梯度\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "            \n",
    "    # 每 100 次训练后查看 loss\n",
    "    if step % 100 == 0:\n",
    "        print(step, \" loss: \", float(loss))\n",
    "        # TensorBoard 可视化操作步骤，写入数据 loss\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"train-loss : \", float(loss), step=step)\n",
    "        \n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        for _, (x, y) in enumerate(ds_val):\n",
    "            # 维度变换\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            # [b, 10]\n",
    "            out = network(x)\n",
    "            # 计算概率最大的位置索引\n",
    "            # out => prob,  [b, 10]\n",
    "            # prob = tf.nn.softmax(out, axis=1)\n",
    "            # [b, 10] => [b] pred\n",
    "            pred = tf.argmax(out, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # 不需要 one_hot 编码\n",
    "            # correct : [b], True: equal; False: not equal\n",
    "            correct = tf.equal(pred, y)\n",
    "            # 将 bool tensor 转换为 int tensor （1或者0） 转换为 numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "            \n",
    "        # compute the accurate\n",
    "        print(step, \"Evaluate Acc : \", total_correct / total)\n",
    "        \n",
    "        # TensorBoard 可视化操作步骤，写入数据 loss and images\n",
    "        # print(x.shape)\n",
    "        val_images = x[:25]\n",
    "        val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\"test-acc\", float(total_correct / total), step=step)\n",
    "            tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "            val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "            figure = image_grid(val_images)\n",
    "            tf.summary.image(\"val-images\", plot_to_image(figure), step=step)\n",
    "            \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 高层接口API 优化并且简化常规的方法代码（集成为接口 API）\n",
    "# 此处 keras 是 TensorFlow 集成的 tf.keras，而不是真正实际上讲的 Keras Keras != tf.keras\n",
    "# API: datasets, layers, losses, metrics, optimizers\n",
    "# from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "# metrics 提供计算记录清空等等一系列关于 metrics 的操作\n",
    "# compile & fit ：Compile => Fit => Evaluate => Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义网络 (可以连接全连接层网络) 实现自己的逻辑需求\n",
    "# keras.Sequential\n",
    "# keras.layers.Layer\n",
    "# keras.Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print(\"datasets: \", x.shape, y.shape, x.min, y.max)\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)])\n",
    "\n",
    "network.build(input_shape=[None, 28*28])\n",
    "network.summary()\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    # 自定义层\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable(\"w\", [inp_dim, outp_dim])\n",
    "        self.bias = self.add_variable(\"b\", [outp_dim])\n",
    "        \n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "        out = inputs @ self.kernel + self.bias\n",
    "        return out\n",
    "\n",
    "# 自定义网络模型\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = MyDense(28*28, 256)\n",
    "        self.fc2 = MyDense(256, 128)        \n",
    "        self.fc3 = MyDense(128, 64)        \n",
    "        self.fc4 = MyDense(64, 32)        \n",
    "        self.fc5 = MyDense(32, 10)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc2(x)        \n",
    "        x = tf.nn.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc4(x)        \n",
    "        x = tf.nn.relu(x)       \n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "#\n",
    "network = MyModel()\n",
    "\n",
    "network.compile(optimizer = optimizers.Adam(lr=0.01),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.fit(db, epochs=5, validation_data=ds_val, validation_freq=2)\n",
    "\n",
    "network.evaluate(ds_val)\n",
    "\n",
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "pred = network.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的保存和加载\n",
    "# save/load weights\n",
    "#==================================================\n",
    "# # save the weights\n",
    "# model.save_weights(\"./checkpoints/my_checkpoint\")\n",
    "# # restore the weights\n",
    "# model = create_model()\n",
    "# model.load_weights(\"./checkpoints/my_checkpoint\")\n",
    "#==================================================\n",
    "# save/load entire model\n",
    "#==================================================\n",
    "# # save entire model\n",
    "# network.save(\"model.h5\")\n",
    "# # load entire model\n",
    "# network = tf.keras.models.load_model(\"model.h5\")\n",
    "#==================================================\n",
    "# saved_model\n",
    "#==================================================\n",
    "# # 工业部署环境\n",
    "# tf.saved_model.save(m, \"./tmp/saved_model/\")\n",
    "# # 加载 loading\n",
    "# imported = tf.saved_model.load(path)\n",
    "# f = imported.signatures[\"serving_default\"]\n",
    "#==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 datasets\n",
    "# 数据集下载太慢的，直接点击显示的网站链接，采用迅雷进行下载，然后手动将数据集储存到指定/user/.keras/datasets/\n",
    "# 自定义网络实战\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0-255] => [-1 -1]\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "# [32, 32, 3]\n",
    "(x, y), (x_val, y_val) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y)\n",
    "y_val = tf.squeeze(y_val)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "y_val = tf.one_hot(y_val, depth=10)\n",
    "print(\"datasets: \", x.shape, y.shape, x_val.shape, y_val.shape, x.min(), x.max())\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "test_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "test_val = test_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    # to replace standard layers.Dense()\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable(\"w\", [inp_dim, outp_dim])\n",
    "        # self.bias = self.add_variable(\"b\", [outp_dim])\n",
    "        \n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "        # x = inputs @ self.kernel + self.bias\n",
    "        x = inputs @ self.kernel\n",
    "        return x\n",
    "\n",
    "# 自定义网络模型\n",
    "class MyNetwork(keras.Model):\n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = MyDense(32*32*3, 256)\n",
    "        self.fc2 = MyDense(256, 128)        \n",
    "        self.fc3 = MyDense(128, 64)        \n",
    "        self.fc4 = MyDense(64, 32)        \n",
    "        self.fc5 = MyDense(32, 10)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        # \n",
    "        x = tf.reshape(inputs, [-1, 32*32*3])\n",
    "        x = self.fc1(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc2(x)        \n",
    "        x = tf.nn.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x) \n",
    "        x = self.fc4(x)        \n",
    "        x = tf.nn.relu(x)       \n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer = optimizers.Adam(lr=1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.fit(train_db, epochs=15, validation_data=test_val, validation_freq=1)\n",
    "network.evaluate(test_val)\n",
    "\n",
    "# 模型权重保存\n",
    "network.save_weights(\"ckpt/weights.ckpt\")\n",
    "del network\n",
    "print(\"saved to ckpt/weights.ckpt\")\n",
    "\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer = optimizers.Adam(lr=1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "# 模型权重加载\n",
    "network.load_weights(\"ckpt/weights.ckpt\")\n",
    "print(\"loaded weights from file.\")\n",
    "network.evaluate(test_val)\n",
    "\n",
    "sample = next(iter(test_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "pred = network.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积 卷积运算 convolution\n",
    "# 卷积神经网络，针对二维图像数据进行处理\n",
    "# feature maps\n",
    "# receptive field\n",
    "# weight sharing\n",
    "\n",
    "# 卷积神经网络\n",
    "# kernel size\n",
    "# padding & stride\n",
    "# channels\n",
    "# pyramid architecture\n",
    "# gradient\n",
    "\n",
    "# 池化和采样\n",
    "# reduce dim\n",
    "# max/avg pooling\n",
    "# upSampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:  (50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,) 0 255\n",
      "batch:  (64, 32, 32, 3) (64,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  12900     \n",
      "=================================================================\n",
      "Total params: 177,124\n",
      "Trainable params: 177,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss:  4.605188369750977\n",
      "0 1 loss:  4.604963302612305\n",
      "0 2 loss:  4.6058125495910645\n",
      "0 3 loss:  4.605375289916992\n",
      "0 8 loss:  4.604780673980713\n",
      "0 9 loss:  4.604815483093262\n",
      "0 10 loss:  4.604935646057129\n",
      "0 11 loss:  4.60479736328125\n",
      "0 16 loss:  4.60684871673584\n",
      "0 17 loss:  4.60480260848999\n",
      "0 18 loss:  4.605024337768555\n",
      "0 19 loss:  4.6037702560424805\n",
      "0 24 loss:  4.604120254516602\n",
      "0 25 loss:  4.6052985191345215\n",
      "0 26 loss:  4.608879089355469\n",
      "0 27 loss:  4.606614589691162\n",
      "0 128 loss:  4.605820178985596\n",
      "0 129 loss:  4.60437536239624\n",
      "0 130 loss:  4.605249404907227\n",
      "0 131 loss:  4.605724334716797\n",
      "0 136 loss:  4.605238437652588\n",
      "0 137 loss:  4.604948997497559\n",
      "0 138 loss:  4.603646278381348\n",
      "0 139 loss:  4.605147361755371\n",
      "0 144 loss:  4.605351448059082\n",
      "0 145 loss:  4.60414981842041\n",
      "0 146 loss:  4.606561660766602\n",
      "0 147 loss:  4.605292320251465\n",
      "0 152 loss:  4.601627349853516\n",
      "0 153 loss:  4.604589462280273\n",
      "0 154 loss:  4.605579853057861\n",
      "0 155 loss:  4.605112075805664\n",
      "0 256 loss:  4.607682228088379\n",
      "0 257 loss:  4.605011940002441\n",
      "0 258 loss:  4.604797840118408\n",
      "0 259 loss:  4.604551315307617\n",
      "0 264 loss:  4.6062822341918945\n",
      "0 265 loss:  4.603349208831787\n",
      "0 266 loss:  4.603877544403076\n",
      "0 267 loss:  4.605881690979004\n",
      "0 272 loss:  4.603941917419434\n",
      "0 273 loss:  4.601945877075195\n",
      "0 274 loss:  4.605957984924316\n",
      "0 275 loss:  4.606285095214844\n",
      "0 280 loss:  4.6018476486206055\n",
      "0 281 loss:  4.610383033752441\n",
      "0 282 loss:  4.604269981384277\n",
      "0 283 loss:  4.604327201843262\n",
      "0 384 loss:  4.558099746704102\n",
      "0 385 loss:  4.568638324737549\n",
      "0 386 loss:  4.5523834228515625\n",
      "0 387 loss:  4.599523544311523\n"
     ]
    }
   ],
   "source": [
    "# CIFAR100 datasets\n",
    "# VGG 13\n",
    "\n",
    "# 13 layers\n",
    "# input -> conv 64 *2 -> max pool -> conv 128 *2 -> max pool -> conv 256 *2 -> max pool \n",
    "# -> conv 512 *2 -> max pool -> conv 512 *2 -> max pool -> Fully connected *3 -> output\n",
    "# [32, 32, 3] => [100]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "# VGG\n",
    "conv_layers = [ # 5 units of conv + max pooling\n",
    "    # unit 1\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "    \n",
    "    # unit 2\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "    \n",
    "    # unit 3\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "    \n",
    "    # unit 4\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\"),\n",
    "    \n",
    "    # unit 5\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding=\"same\")]\n",
    "\n",
    "# \n",
    "def preprocess(x, y):\n",
    "    # [0-255] => [0-1]\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "# [32, 32, 3]\n",
    "(x, y), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(\"datasets: \", x.shape, y.shape, x_test.shape, y_test.shape, x.min(), x.max())\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(64)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "def main():\n",
    "    # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "    conv_net = Sequential(conv_layers)\n",
    "    # conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "    # test the conv_net\n",
    "    # x = tf.random.normal([4, 32, 32, 3])\n",
    "    # out = conv_net(x)\n",
    "    # print(out.shape)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc_net = Sequential([\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(100, activation=tf.nn.relu),])\n",
    "    #\n",
    "    conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "    fc_net.build(input_shape=[None, 512])\n",
    "    conv_net.summary()\n",
    "    fc_net.summary()\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=1e-4)\n",
    "    \n",
    "    # [1, 2] + [3, 4] = [1, 2, 3, 4]\n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    \n",
    "    #\n",
    "    for epoch in range(50):\n",
    "        #\n",
    "        for step, (x, y) in enumerate(train_db):\n",
    "            #\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "                out = conv_net(x)\n",
    "                # squeeze/flatten\n",
    "                out = tf.reshape(out, [-1, 512])\n",
    "                # [b, 512] => [b, 100]\n",
    "                logits = fc_net(out)\n",
    "                # [b] => [b, 100]\n",
    "                y_onehot = tf.one_hot(y, depth=100)\n",
    "                # compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            # \n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "            \n",
    "            #\n",
    "            if step & 100 == 0:\n",
    "                print(epoch, step, \"loss: \", float(loss))\n",
    "        \n",
    "        #\n",
    "        total_num, total_correct = 0., 0\n",
    "        for x, y in test_db:\n",
    "            \n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            logits = fc_net(out)\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "            correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "            correct += tf.reduce_sum(correct)\n",
    "            \n",
    "            total_num += x.shape[0]\n",
    "            total_correct += int(correct)\n",
    "            \n",
    "        # compute the accurate\n",
    "        print(epoch, \"Evaluate Acc : \", total_correct / total_num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \" __main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经典卷积神经网络  CNN  CV方向（CNN）\n",
    "# ImageNet: LeNet5(80年代) => AlexNet(2012年) => VGG(2014年) => GoogLeNet(2014年) => ResNet(2015年)\n",
    "# ResNet  &  DenseNet\n",
    "#\n",
    "# =====================================================================================^_^ ^_^ ^-^\n",
    "# ^_^ ^_^ ^_^ ^_^  进入 search，而不是停留在看看别人的博客、跑跑别人的代码、并没有太大的意义，  \n",
    "# ^_^ ^_^ 要投入到一线的科研中，要么为学术界做出贡献，要么利用最新技术为工业界、工程界做出贡献，\n",
    "# ^_^ ^_^ ^_^ ^_^ 老是学别人的东西，这种行为其实没有产生价值   ^_^ ^_^ ^_^ ^_^ \n",
    "# ^_^ ^_^                                                      ^_^ ^_^ \n",
    "# ^_^                                                            ^_^ \n",
    "# ======================================================================================^_^ ^_^ ^-^\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "# basic block\n",
    "class BasicBlock(layers.Layer):\n",
    "    #\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(filter_num, (3, 3), strides=stride, padding=\"same\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation(\"relu\")\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(filter_num, (3, 3), strides=1, padding=\"same\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1:\n",
    "            self.downsample = Sequential()\n",
    "            self.downsample.add(layers.Conv2D(filter_num, (1, 1), strides=stride))\n",
    "        else:\n",
    "            self.downsample = lambda x:x\n",
    "            \n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, h, w, c]\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        identity = self.downsample(inputs)\n",
    "        \n",
    "        output = layers.add([out, identity])\n",
    "        output = tf.nn.relu(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Res block\n",
    "class ResNet(keras.Model):\n",
    "    #\n",
    "    def __init__(self, layer_dims, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.stem = Sequential([layers.Conv2D(64, (3, 3), strides=(1, 1)),\n",
    "                                layers.BatchNormalization(),\n",
    "                                layers.Activation(\"relu\"),\n",
    "                                layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\")])\n",
    "        \n",
    "        self.layer1 = self.build_resblock(64,  layer_dims[0])\n",
    "        self.layer2 = self.build_resblock(128, layer_dims[1], stride=2)\n",
    "        self.layer3 = self.build_resblock(256, layer_dims[2], stride=2)\n",
    "        self.layer4 = self.build_resblock(512, layer_dims[3], stride=2)\n",
    "        \n",
    "        # output: [b, 512, h, w]\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "        #\n",
    "        x = self.stem(inputs)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # [b, c]\n",
    "        x = self.avgpool(x)\n",
    "        # [b, 100]\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #\n",
    "    def build_resblock(self, filter_num, blocks, stride=1):\n",
    "        #\n",
    "        res_blocks = Sequential()\n",
    "        # may down sample\n",
    "        res_blocks.add(BasicBlock(filter_num, stride))\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            res_blocks.add(BasicBlock(filter_num, stride=1))\n",
    "        \n",
    "        return res_blocks\n",
    "    \n",
    "#\n",
    "def resnet18():\n",
    "    # 4 * 4 + 1 + 1 = 18\n",
    "    return ResNet([2, 2, 2, 2])\n",
    "\n",
    "#\n",
    "def resnet34():\n",
    "    return ResNet([3, 4, 6, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets:  (50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,) 0 255\n",
      "batch:  (64, 32, 32, 3) (64,)\n",
      "Model: \"res_net_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_16 (Sequential)   multiple                  2048      \n",
      "_________________________________________________________________\n",
      "sequential_17 (Sequential)   multiple                  148736    \n",
      "_________________________________________________________________\n",
      "sequential_18 (Sequential)   multiple                  526976    \n",
      "_________________________________________________________________\n",
      "sequential_20 (Sequential)   multiple                  2102528   \n",
      "_________________________________________________________________\n",
      "sequential_22 (Sequential)   multiple                  8399360   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  51300     \n",
      "=================================================================\n",
      "Total params: 11,230,948\n",
      "Trainable params: 11,223,140\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n",
      "0 0 loss:  4.609555244445801\n",
      "0 1 loss:  4.603026390075684\n",
      "0 2 loss:  4.6128034591674805\n",
      "0 3 loss:  4.626725673675537\n"
     ]
    }
   ],
   "source": [
    "# ResNet 18\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "# loading ResNet18\n",
    "# from resnet import resnet18\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# \n",
    "def preprocess(x, y):\n",
    "    # [0-255] => [0-1]\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "# [32, 32, 3]\n",
    "(x, y), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(\"datasets: \", x.shape, y.shape, x_test.shape, y_test.shape, x.min(), x.max())\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(64)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(\"batch: \", sample[0].shape, sample[1].shape)\n",
    "\n",
    "# \n",
    "def main():\n",
    "    # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "    model = resnet18()\n",
    "    model.build(input_shape=(None, 32, 32, 3))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=1e-4)\n",
    "    \n",
    "    #\n",
    "    for epoch in range(50):\n",
    "        #\n",
    "        for step, (x, y) in enumerate(train_db):\n",
    "            #\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 32, 32, 3] => [b, 100]\n",
    "                logits = model(x)\n",
    "                # [b] => [b, 100]\n",
    "                y_onehot = tf.one_hot(y, depth=100)\n",
    "                # compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            # \n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "            #\n",
    "            if step & 100 == 0:\n",
    "                print(epoch, step, \"loss: \", float(loss))\n",
    "        \n",
    "        #\n",
    "        total_num, total_correct = 0., 0\n",
    "        for x, y in test_db:\n",
    "            \n",
    "            logits = model(x)\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "            correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "            correct += tf.reduce_sum(correct)\n",
    "            \n",
    "            total_num += x.shape[0]\n",
    "            total_correct += int(correct)\n",
    "            \n",
    "        # compute the accurate\n",
    "        print(epoch, \"Evaluate Acc : \", total_correct / total_num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \" __main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间序列\n",
    "# sequence embedding\n",
    "# batch\n",
    "# 文本序列\n",
    "# word emmbedding\n",
    "# embedding layer\n",
    "# 图像、声音、视频、文本等等序列，转换为数字型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test shape:  (25000, 80)\n",
      "Epoch 1/4\n",
      "195/195 [==============================] - 30s 155ms/step - loss: 0.5179 - accuracy: 0.7275 - val_loss: 0.4049 - val_accuracy: 0.8238\n",
      "Epoch 2/4\n",
      "195/195 [==============================] - 27s 138ms/step - loss: 0.3056 - accuracy: 0.8738 - val_loss: 0.3960 - val_accuracy: 0.8336\n",
      "Epoch 3/4\n",
      "195/195 [==============================] - 27s 139ms/step - loss: 0.1906 - accuracy: 0.9285 - val_loss: 0.4417 - val_accuracy: 0.8162\n",
      "Epoch 4/4\n",
      "195/195 [==============================] - 27s 141ms/step - loss: 0.0887 - accuracy: 0.9702 - val_loss: 0.5652 - val_accuracy: 0.8161\n",
      "Model: \"my_rnn_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      multiple                  1000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_cell_7 (SimpleRNN multiple                  10560     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 1,010,625\n",
      "Trainable params: 1,010,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 循环神经网络 RNN   NLP方向（RNN）\n",
    "# folded model\n",
    "# formulation\n",
    "# simple RNN cell\n",
    "# single layer RNN Cell\n",
    "# Multi-Layers RNN\n",
    "# RNN Layer\n",
    "\n",
    "\n",
    "# 情感分类 \n",
    "# 评论分析\n",
    "# sentiment analysis\n",
    "# two approaches\n",
    "#\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "batchsz = 128\n",
    "\n",
    "# the most frequent words\n",
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "embedding_len = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
    "# x_train : [b, 80] , number\n",
    "# x_test : [b, 80]\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "print(\"x_train shape: \", x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "\n",
    "# \n",
    "class MyRNN(keras.Model):\n",
    "    # \n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "        \n",
    "        # [b, 64]\n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        \n",
    "        # transform text to embedding representation\n",
    "        # [b, 80] => [b, 80, 100]\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        \n",
    "        # [b, 80, 100] , h_dim : 64\n",
    "        # RNN : cell1, cell2, cell3\n",
    "        # simpleRNN\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.2)\n",
    "\n",
    "        # fc, [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 80]\n",
    "        x = inputs \n",
    "        # embedding: [b, 80] => [b, 80, 100]\n",
    "        x = self.embedding(x)\n",
    "        # rnn cell compute,[b, 80, 100] => [b, 64]\n",
    "        state0 = self.state0\n",
    "        for word in tf.unstack(x, axis=1):\n",
    "            out, state1 = self.rnn_cell0(word, state0)\n",
    "            state0 = state1\n",
    "            \n",
    "        # out: [b, 64]\n",
    "        x = self.outlayer(out)\n",
    "        # p(y is pos|x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "#\n",
    "def main():\n",
    "    units = 64\n",
    "    epochs = 4\n",
    "    \n",
    "    model = MyRNN(units)\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
    "                  loss = tf.losses.BinaryCrossentropy(),\n",
    "                  metrics = [\"accuracy\"])\n",
    "    model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
    "    model.summary()\n",
    "    \n",
    "# if __name__ == \" __main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "Model: \"ae_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_8 (Sequential)    multiple                  236436    \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    multiple                  237200    \n",
      "=================================================================\n",
      "Total params: 473,636\n",
      "Trainable params: 473,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 0.69310462474823\n",
      "0 100 0.33316338062286377\n",
      "1 0 0.32585394382476807\n",
      "1 100 0.3060133457183838\n",
      "2 0 0.3012106418609619\n",
      "2 100 0.30313393473625183\n",
      "3 0 0.3004123270511627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e69eab257c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mx_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mx_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0msava_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./image/ae_images/rec_epoch_%d.png\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-e69eab257c94>\u001b[0m in \u001b[0;36msava_images\u001b[1;34m(imgs, name)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mnew_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m             \u001b[0msave_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m             \u001b[1;31m# do what we can to clean up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\PIL\\PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[0;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb\"eXIf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m     \u001b[0mImageFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"zip\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb\"IEND\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Auto-Encoders\n",
    "# Variational Auto-Encoders\n",
    "\n",
    "# 梯度爆炸 问题\n",
    "# 梯度离散 问题\n",
    "# supervised learning\n",
    "# massive unlabeled data in real life world\n",
    "# unsupervised learning\n",
    "# reinforcement learning\n",
    "# PAC 降维\n",
    "# 数据集维度降维可视化\n",
    "# http://projector.tensorflow.org/\n",
    "# VAE & GAN\n",
    "\n",
    "\n",
    "# Auto-Encoders\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(22)\n",
    "\n",
    "def sava_images(imgs, name):\n",
    "    new_im = Image.new(\"L\", (280, 280))\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im, mode=\"L\")\n",
    "            new_im.paste(im, (i, j))\n",
    "            index += 1\n",
    "            \n",
    "    # \n",
    "    new_im.save(name)\n",
    "    \n",
    "#\n",
    "h_dim = 20\n",
    "batchsz = 512\n",
    "lr = 1e-3\n",
    "\n",
    "# loading dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255., x_test.astype(np.float32) / 255.\n",
    "# unsupervised learning do not need label\n",
    "train_db = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db = train_db.shuffle(batchsz * 5).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_db = test_db.batch(batchsz)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# auto-encoders\n",
    "class AE(keras.Model):\n",
    "    #\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        \n",
    "        # Encoders\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(256, activation=tf.nn.relu),\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(h_dim) ])\n",
    "\n",
    "        # Decoders\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(256, activation=tf.nn.relu),\n",
    "            layers.Dense(784) ])\n",
    "\n",
    "        \n",
    "    # 前向传播\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 784] => [b, 10]\n",
    "        h = self.encoder(inputs)\n",
    "        # [b, 10] => [b, 784]\n",
    "        x_hat = self.decoder(h)\n",
    "\n",
    "        return x_hat\n",
    "    \n",
    "#\n",
    "model = AE()\n",
    "model.build(input_shape=(None, 784))\n",
    "model.summary()\n",
    "\n",
    "# 注意命名空间的改变 keras 或者 tf\n",
    "optimizer = tf.optimizers.Adam(lr=lr)\n",
    "\n",
    "# \n",
    "for epoch in range(100):\n",
    "    #\n",
    "    for step, x in enumerate(train_db):\n",
    "        #[b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        # \n",
    "        with tf.GradientTape() as tape:\n",
    "            x_rec_logits = model(x)\n",
    "\n",
    "            rec_loss = tf.losses.binary_crossentropy(x, x_rec_logits, from_logits=True)\n",
    "            rec_loss = tf.reduce_mean(rec_loss)\n",
    "\n",
    "        # \n",
    "        grads = tape.gradient(rec_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "\n",
    "        if step % 100 ==0:\n",
    "            print(epoch, step, float(rec_loss))\n",
    "\n",
    "\n",
    "        # evaluation\n",
    "        x = next(iter(test_db))\n",
    "        logits = model(tf.reshape(x, [-1, 784]))\n",
    "        x_hat = tf.sigmoid(logits)\n",
    "        # [b, 784] => [b, 28, 28]\n",
    "        x_hat = tf.reshape(x_hat, [-1, 28, 28])\n",
    "\n",
    "        # [b, 28, 28] => [2b, 28, 28]\n",
    "        x_concat = tf.concat([x, x_hat], axis=0)\n",
    "        x_concat = x_hat\n",
    "        x_concat = x_concat.numpy() * 255.\n",
    "        x_concat = x_concat.astype(np.uint8)\n",
    "        # 记得创建文件夹\n",
    "        sava_images(x_concat, \"./image/ae_images/rec_epoch_%d.png\"%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "Model: \"vae_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             multiple                  1408      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             multiple                  101136    \n",
      "=================================================================\n",
      "Total params: 205,604\n",
      "Trainable params: 205,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 kl div: 3.0320773124694824 rec loss: 544.954833984375\n",
      "0 100 kl div: 15.58360481262207 rec loss: 290.41473388671875\n",
      "1 0 kl div: 15.099756240844727 rec loss: 285.81939697265625\n",
      "1 100 kl div: 16.10059928894043 rec loss: 257.8894958496094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-90999159aea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrec_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1686\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1688\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1689\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5565\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5566\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5567\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5568\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5569\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Variational Auto-Encoders\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, losses, optimizers, Sequential, metrics\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(22)\n",
    "\n",
    "def sava_images(imgs, name):\n",
    "    new_im = Image.new(\"L\", (280, 280))\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im, mode=\"L\")\n",
    "            new_im.paste(im, (i, j))\n",
    "            index += 1\n",
    "    # \n",
    "    new_im.save(name)\n",
    "    \n",
    "#\n",
    "h_dim = 20\n",
    "batchsz = 512\n",
    "lr = 1e-3\n",
    "\n",
    "# loading dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255., x_test.astype(np.float32) / 255.\n",
    "# unsupervised learning do not need label\n",
    "train_db = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db = train_db.shuffle(batchsz * 5).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_db = test_db.batch(batchsz)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "z_dim = 10\n",
    "\n",
    "# Variational Auto-Encoders\n",
    "class VAE(keras.Model):\n",
    "    #\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.fc1 = layers.Dense(128)\n",
    "        self.fc2 = layers.Dense(z_dim) # get mean prediction\n",
    "        self.fc3 = layers.Dense(z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc4 = layers.Dense(128)\n",
    "        self.fc5 = layers.Dense(784)\n",
    "        \n",
    "    #\n",
    "    def encoder(self, x):\n",
    "        # \n",
    "        h = tf.nn.relu(self.fc1(x))\n",
    "        # get mean\n",
    "        mu = self.fc2(h)\n",
    "        # get variance\n",
    "        log_var = self.fc3(h)\n",
    "\n",
    "        return mu, log_var\n",
    "    \n",
    "    #\n",
    "    def decoder(self, z):\n",
    "\n",
    "        out = tf.nn.relu(self.fc4(z))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # \n",
    "    def reparameterize(self, mu, log_var):\n",
    "\n",
    "        eps = tf.random.normal(log_var.shape)\n",
    "\n",
    "        std = tf.exp(log_var*0.5)\n",
    "\n",
    "        z = mu + std * eps\n",
    "        return z\n",
    "    \n",
    "    #\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        # [b, 784] => [b, z_dim], [b, z_dim]\n",
    "        mu, log_var = self.encoder(inputs)\n",
    "        # reparameterization trick\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        return x_hat, mu, log_var\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "model.build(input_shape=(4, 784))\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "# \n",
    "for epoch in range(1000):\n",
    "    #\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        \n",
    "        #\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_rec_logits, mu, log_var = model(x)\n",
    "\n",
    "            rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=x_rec_logits)\n",
    "            rec_loss = tf.reduce_sum(rec_loss) / x.shape[0]\n",
    "\n",
    "            # compute kl divergence (mu, var) ~ N (0, 1)\n",
    "            # https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "            kl_div = -0.5 * (log_var + 1 - mu**2 - tf.exp(log_var))\n",
    "            kl_div = tf.reduce_sum(kl_div) / x.shape[0]\n",
    "\n",
    "            loss = rec_loss + 1. * kl_div\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'kl div:', float(kl_div), 'rec loss:', float(rec_loss))\n",
    "\n",
    "\n",
    "    # evaluation\n",
    "    z = tf.random.normal((batchsz, z_dim))\n",
    "    logits = model.decoder(z)\n",
    "    x_hat = tf.sigmoid(logits)\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28]).numpy() *255.\n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    sava_images(x_hat, './image/vae_images/sampled_epoch%d.png'%epoch)\n",
    "\n",
    "    x = next(iter(test_db))\n",
    "    x = tf.reshape(x, [-1, 784])\n",
    "    x_hat_logits, _, _ = model(x)\n",
    "    x_hat = tf.sigmoid(x_hat_logits)\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28]).numpy() *255.\n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    # 记得创建文件夹\n",
    "    sava_images(x_hat, './image/vae_images/rec_epoch%d.png'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对抗生成网络 GAN\n",
    "#\n",
    "# What I cannot create, I do not understand.  —— Richard Felnman\n",
    "# ^_^ ^_^\n",
    "# 复现很重要\n",
    "# \n",
    "# 数据分布\n",
    "# 回家的成长历程\n",
    "# GAN 原理\n",
    "# 纳什均衡-D\n",
    "# 纳什均衡-G\n",
    "#\n",
    "# A~Z GAN  : https://github.com/hindupuravinash/the-gan-zoo\n",
    "#\n",
    "# KL Divergence & JS Divergence\n",
    "# JS 散度的缺陷\n",
    "# VAE & DCGAN\n",
    "# EM 距离\n",
    "# \n",
    "# WGAN-GP 原理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.23398143]\n",
      " [-0.12207203]], shape=(2, 1), dtype=float32)\n",
      "(2, 54, 54, 3)\n"
     ]
    }
   ],
   "source": [
    "# dataset Anime 动漫图像\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from    tensorflow.keras import layers\n",
    "\n",
    "# \n",
    "class Generator(keras.Model):\n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #  z: [b, 100] => [b, 3*3*512] => [b, 3, 3, 512] => [b, 64, 64, 3]\n",
    "        self.fc = layers.Dense(3*3*512)\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv2 = layers.Conv2DTranspose(128, 5, 2, 'same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'same')\n",
    "        \n",
    "    # \n",
    "    def call(self, inputs, training=None):\n",
    "        # [z, 100] => [z, 3*3*512]\n",
    "        x = self.fc(inputs)\n",
    "        x = tf.reshape(x, [-1, 3, 3, 512])\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        # \n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = self.conv3(x)\n",
    "        x = tf.tanh(x) \n",
    "\n",
    "        return x\n",
    "\n",
    "# \n",
    "class Discriminator(keras.Model):\n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # [b, 64, 64, 3] => [b, 1]\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv1 = layers.Conv2D(64, 5, 3, 'valid')\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv2 = layers.Conv2D(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        # CNN layer\n",
    "        self.conv3 = layers.Conv2D(256, 5, 3, 'valid')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        # [b, h, w, 3] => [b, -1] \n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "    # \n",
    "    def call(self, inputs, training=None):\n",
    "        #\n",
    "        x = tf.nn.leaky_relu(self.conv1(inputs))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "\n",
    "        # [b, h, w, 3] => [b, -1] \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # [b, -1] => [b, 1]\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# test net\n",
    "def main():\n",
    "    # \n",
    "    d = Discriminator()\n",
    "    g = Generator()\n",
    "\n",
    "    x = tf.random.normal([2, 64, 64, 3])\n",
    "    z = tf.random.normal([2, 100])\n",
    "\n",
    "    prob = d(x)\n",
    "    print(prob)\n",
    "    x_hat = g(z)\n",
    "    print(x_hat.shape)\n",
    "    \n",
    "#\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集 loading dataset\n",
    "\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "# \n",
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "\n",
    "    # @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        # img = tf.image.random_crop(img,[resize, resize])\n",
    "        # img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1 #-1~1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "# \n",
    "def batch_dataset(dataset,\n",
    "                  batch_size,\n",
    "                  drop_remainder=True,\n",
    "                  n_prefetch_batch=1,\n",
    "                  filter_fn=None,\n",
    "                  map_fn=None,\n",
    "                  n_map_threads=None,\n",
    "                  filter_after_map=False,\n",
    "                  shuffle=True,\n",
    "                  shuffle_buffer_size=None,\n",
    "                  repeat=None):\n",
    "    # set defaults\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n",
    "\n",
    "    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "    else:  # [*] this is slower\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# \n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                              batch_size,\n",
    "                              drop_remainder=True,\n",
    "                              n_prefetch_batch=1,\n",
    "                              filter_fn=None,\n",
    "                              map_fn=None,\n",
    "                              n_map_threads=None,\n",
    "                              filter_after_map=False,\n",
    "                              shuffle=True,\n",
    "                              shuffle_buffer_size=None,\n",
    "                              repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                            batch_size,\n",
    "                            drop_remainder=drop_remainder,\n",
    "                            n_prefetch_batch=n_prefetch_batch,\n",
    "                            filter_fn=filter_fn,\n",
    "                            map_fn=map_fn,\n",
    "                            n_map_threads=n_map_threads,\n",
    "                            filter_after_map=filter_after_map,\n",
    "                            shuffle=shuffle,\n",
    "                            shuffle_buffer_size=shuffle_buffer_size,\n",
    "                            repeat=repeat)\n",
    "    return dataset\n",
    "\n",
    "# \n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else:\n",
    "        memory_data = (img_paths, labels)\n",
    "\n",
    "    def parse_fn(path, *label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # fix channels to 3\n",
    "        return (img,) + label\n",
    "\n",
    "    if map_fn:  # fuse `map_fn` and `parse_fn`\n",
    "        def map_fn_(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "\n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "    # \n",
    "    return dataset\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (512, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(512, 64, 64, 3) 1.0 -1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3a9d3da6de8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;31m# if __name__ == '__main__':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;31m#     main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-3a9d3da6de8b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0md_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    600\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m           data_format=data_format)\n\u001b[0m\u001b[0;32m    603\u001b[0m   ]\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1079\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \"dilations\", dilations)\n\u001b[0m\u001b[0;32m   1082\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GAN training\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# \n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)\n",
    "\n",
    "# \n",
    "def celoss_ones(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.ones_like(logits))\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# \n",
    "def celoss_zeros(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.zeros_like(logits))\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# \n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 1. treat real image as real\n",
    "    # 2. treat generated image as fake\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    \n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    \n",
    "    loss = d_loss_fake + d_loss_real\n",
    "\n",
    "    return loss\n",
    "\n",
    "# \n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    # \n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def main():\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # hyper-parameters\n",
    "    z_dim = 100 \n",
    "    epochs = 3000000 \n",
    "    batch_size = 512\n",
    "    learning_rate = 0.0002\n",
    "    is_training = True\n",
    "\n",
    "    # loading dataset\n",
    "    img_path = glob.glob(\"./datasets/images/*.jpg\")\n",
    "    \n",
    "    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)\n",
    "    print(dataset, img_shape)\n",
    "    sample = next(iter(dataset))\n",
    "    print(sample.shape, tf.reduce_max(sample).numpy(), tf.reduce_min(sample).numpy())\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    db_iter = iter(dataset)\n",
    "\n",
    "    # \n",
    "    generator = Generator()\n",
    "    generator.build(input_shape = (None, z_dim))\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.build(input_shape=(None, 64, 64, 3))\n",
    "    \n",
    "    # \n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "\n",
    "    # \n",
    "    for epoch in range(epochs): \n",
    "        # \n",
    "        for _ in range(1):\n",
    "            # \n",
    "            batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)\n",
    "            batch_x = next(db_iter)\n",
    "            \n",
    "            # train D\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "                \n",
    "            # \n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "        \n",
    "        \n",
    "        # \n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "            \n",
    "        # \n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "        # \n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, 'd-loss: ',float(d_loss), 'g-loss: ', float(g_loss))\n",
    "            # \n",
    "            z = tf.random.uniform([100, z_dim])\n",
    "            fake_image = generator(z, training=False)\n",
    "            img_path = os.path.join('image', 'gan-%d.png'%epoch)\n",
    "            save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (512, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(512, 64, 64, 3) 1.0 -1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d0b8a4548cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;31m# if __name__ == '__main__':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;31m#     main()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-d0b8a4548cb7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;31m# train D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d0b8a4548cb7>\u001b[0m in \u001b[0;36md_loss_fn\u001b[1;34m(generator, discriminator, batch_z, batch_x, is_training)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# 1. treat real image as real\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m# 2. treat generated image as fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mfake_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0md_fake_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0md_real_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-ca39a5f3633f>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m         dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[1;34m(x, kernel, output_shape, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   5037\u001b[0m     x = nn.conv2d_transpose(x, kernel, output_shape, strides,\n\u001b[0;32m   5038\u001b[0m                             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5039\u001b[1;33m                             data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   5040\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5041\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[1;34m(value, filter, output_shape, strides, padding, data_format, name, input, filters, dilations)\u001b[0m\n\u001b[0;32m   2212\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2213\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2214\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose_v2\u001b[1;34m(input, filters, output_shape, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2289\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2290\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2291\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m         \"dilations\", dilations)\n\u001b[0m\u001b[0;32m   1242\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# WGAN-GP\n",
    "# GAN training\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# \n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)\n",
    "\n",
    "# \n",
    "def celoss_ones(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.ones_like(logits))\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# \n",
    "def celoss_zeros(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.zeros_like(logits))\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# \n",
    "def gradient_penalty(discriminator, batch_x, fake_image):\n",
    "    #\n",
    "    batchsz = batch_x.shape[0]\n",
    "    \n",
    "    # [b, h, w, c]\n",
    "    t = tf.random.uniform([batchsz, 1, 1, 1])\n",
    "    # [b, 1, 1, 1] => [b, h, w, c]\n",
    "    t = tf.broadcast_to(t, batch_x.shape)\n",
    "    \n",
    "    interplate = t * batch_x + (1 - t) * fake_image\n",
    "    \n",
    "    # \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([interplate])\n",
    "        d_interplote_logits = discriminator(interplate)\n",
    "        \n",
    "    #\n",
    "    grads = tape.gradient(d_interplote_logits, interplate)\n",
    "    # grads : [b, h, w, c]\n",
    "    grads = tf.reshape(grads, [grads.shape[0], -1])\n",
    "    gp = tf.norm(grads, axis=1)\n",
    "    gp = tf.reduce_mean((gp-1)**2)\n",
    "    \n",
    "    return gp\n",
    "\n",
    "# \n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 1. treat real image as real\n",
    "    # 2. treat generated image as fake\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    \n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    \n",
    "    # WGAN-GP\n",
    "    gp = gradient_penalty(discriminator, batch_x, fake_image)\n",
    "    \n",
    "    # WGAN-GP\n",
    "    loss = d_loss_fake + d_loss_real + gp\n",
    "\n",
    "    return loss, gp\n",
    "\n",
    "# \n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    # \n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def main():\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # hyper-parameters\n",
    "    z_dim = 100 \n",
    "    epochs = 3000000 \n",
    "    batch_size = 512\n",
    "    learning_rate = 0.0002\n",
    "    is_training = True\n",
    "\n",
    "    # loading dataset\n",
    "    # kaggle link : https://www.kaggle.com/splcher/animefacedataset\n",
    "    img_path = glob.glob(\"./datasets/images/*.jpg\")\n",
    "    \n",
    "    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)\n",
    "    print(dataset, img_shape)\n",
    "    sample = next(iter(dataset))\n",
    "    print(sample.shape, tf.reduce_max(sample).numpy(), tf.reduce_min(sample).numpy())\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    db_iter = iter(dataset)\n",
    "\n",
    "    # \n",
    "    generator = Generator()\n",
    "    generator.build(input_shape = (None, z_dim))\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.build(input_shape=(None, 64, 64, 3))\n",
    "    \n",
    "    # \n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "\n",
    "    # \n",
    "    for epoch in range(epochs): \n",
    "        # \n",
    "        for _ in range(1):\n",
    "            # \n",
    "            batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)\n",
    "            batch_x = next(db_iter)\n",
    "            \n",
    "            # train D\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "                \n",
    "            # \n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "        \n",
    "        \n",
    "        # \n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "            \n",
    "        # \n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "        # \n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, 'd-loss: ',float(d_loss), 'g-loss: ', float(g_loss), 'gp: ', float(gp))\n",
    "            # \n",
    "            z = tf.random.uniform([100, z_dim])\n",
    "            fake_image = generator(z, training=False)\n",
    "            img_path = os.path.join('image', 'wgan-%d.png'%epoch)\n",
    "            save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生物神经元结构 1959年\n",
    "# Perceptron \n",
    "# 感知器提出\n",
    "# Multi-Output Perceptron 1961年\n",
    "# 1969年，perceptrons' limitation\n",
    "# Multi-Layer Perceptron is coming\n",
    "# Backpropagation\n",
    "# Rediscover 1986 on Nature\n",
    "# CNN and LSTM(1997年)\n",
    "\n",
    "# 深度学习的诞生\n",
    "# Another Hero：NVIDIA  2009\n",
    "# BOOM 2012 DCNN Deep Convolutional Neural Networks\n",
    "# big data、 relu、 batchnorm、Xavier Inititalization、Kaiming Initialization、dropout\n",
    "# OpenAI Five \n",
    "# Baidu Apollo\n",
    "\n",
    "# Deep Learning : Big Data(ImageNet) + Deep Convolutional Neural Nerword + Backprop on GPU = Learned Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
